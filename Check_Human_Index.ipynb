{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4, ssl\n",
    "import pandas as pd\n",
    "import re\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.error import HTTPError\n",
    "import time\n",
    "import datetime, time # for sleep\n",
    "import platform\n",
    "from urllib.parse import quote\n",
    "\n",
    "# SDS Proxy\n",
    "# import os\n",
    "# os.environ[\"HTTP_PROXY\"] = \"http://70.10.15.10:8080\"\n",
    "# os.environ[\"HTTPS_PROXY\"] = \"http://70.10.15.10:8080\"\n",
    "# os.environ[\"PYTHONHTTPSVERIFY\"] = \"0\"\n",
    "\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                            'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                            'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "            'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "            'Accept-Encoding': 'none', \\\n",
    "            'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "            'Connection': 'keep-alive'}\n",
    "\n",
    "def __Last_Page_Numb_Market(Market) :\n",
    "    if Market == \"KOSPI\" :\n",
    "        url = \"https://finance.naver.com/sise/sise_index_day.nhn?code=KOSPI&page=1\"\n",
    "        # print(url)\n",
    "    elif Market == \"KOSDAQ\" :\n",
    "        url = \"https://finance.naver.com/sise/sise_index_day.nhn?code=KOSDAQ&page=1\"\n",
    "        # print(url)\n",
    "\n",
    "    html = urlopen(url, context=context)\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    main1_pages = bs_object.find_all(\"a\")\n",
    "    for a_list in main1_pages:\n",
    "        if a_list is main1_pages[-1] :\n",
    "            last_page=a_list.attrs['href']\n",
    "        else :\n",
    "            continue\n",
    "        page_num: object=last_page.split('=')\n",
    "        print(\"# Market Page_Number : \", page_num[2])\n",
    "        return page_num[2]\n",
    "\n",
    "def __Market_Price(company_code, page):\n",
    "    df_list, date_list, closing_list = [], [], []\n",
    "    # print(\"# Market : %s\" % company_code)\n",
    "\n",
    "    print(\"# Company : %s\" % company_code)\n",
    "    page = int(page)\n",
    "    # for page_num in range(1, page) :\n",
    "    for page_num in range(1, 200) :\n",
    "        url_main = \"https://finance.naver.com/sise/sise_index_day.nhn?code=\" + company_code + \"&page=\" + str(page_num)\n",
    "        # print(\"# url : %s\" % url_main)\n",
    "        code_data = pd.read_html(url_main, header=0, skiprows=(6,7,8)) # ---> code data로 출력을 생성하면 NaN이 1개라인이 남음, Type은 <class 'list'>\n",
    "        df_list.append(pd.read_html(url_main)[0]) # ---> List 로 append, 본문[0]과 페이지 출력[1] 부분 중 본문을 출력\n",
    "\n",
    "    df=pd.concat(df_list)\n",
    "    df.dropna(subset=[\"날짜\"], inplace=True) # ---> Naver에서 출력되는 가운데 날짜 컬럼 NaN 라인들 삭제처리\n",
    "    df.rename(columns={'날짜': 'date'}, inplace = True)\n",
    "    df.rename(columns={'체결가': 'closing'}, inplace = True)\n",
    "    df.rename(columns={'전일비': 'diff'}, inplace = True)\n",
    "    df['new_date'] = pd.to_datetime(df['date']) # ---> dateime 형식으로 new_date 추가\n",
    "    date_list=df.date.values.tolist()\n",
    "    closing_list=df.closing.values.tolist()\n",
    "    for x in range(0, len(closing_list)-1):\n",
    "        closing_list[x] = int(closing_list[x]) # ---> float 에서 int로 변경\n",
    "\n",
    "    # date_list.reverse()\n",
    "    # closing_list.reverse()\n",
    "\n",
    "    return date_list, closing_list\n",
    "\n",
    "def __DC_Last_Page_Find(page) :\n",
    "\n",
    "    print(\"# DCinside Function Start\")\n",
    "    Table_DF = pd.DataFrame()\n",
    "\n",
    "    for page_num in range(1,page) :\n",
    "        sleep_count = page_num % 10\n",
    "        if sleep_count == 0 :\n",
    "            print(\"# Sleep Time : 10s\")\n",
    "            print(\"# Sleep Count : %s\" % sleep_count)\n",
    "            time.sleep(10)\n",
    "        else :\n",
    "            time.sleep(2)\n",
    "\n",
    "        url = \"https://gall.dcinside.com/board/lists/?id=neostock&page=\" + str(page_num)\n",
    "        print(url)\n",
    "\n",
    "        req = Request(url=url, headers=headers)\n",
    "\n",
    "        try :\n",
    "            html = urlopen(req).read()\n",
    "            # html = urlopen(url, context=context)\n",
    "        except HTTPError as err:\n",
    "            if err.code == 404 :\n",
    "                print(\"# Error HTTP : 404\")\n",
    "                return\n",
    "            elif err.code == 403 :\n",
    "                print(\"# Error HTTP : 403\")\n",
    "                return\n",
    "            elif err.code == 500 :\n",
    "                print(\"# Error HTTP : 500\")\n",
    "                return\n",
    "            elif err.code == 505:\n",
    "                print(\"# Error HTTP : 505\")\n",
    "                return\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "        # print(bs_object)\n",
    "        table1 = bs_object.find_all(\"table\", {'class' : 'gall_list'})\n",
    "        table2 = bs_object.find_all(\"td\", {'class' : 'gall_date'})\n",
    "        # print(table)\n",
    "        # print(test)\n",
    "        table_data = pd.read_html(str(table1), header=0) # ---> pd.read_html은 List 형태로 보내고 그 안에 DataFrame\n",
    "        Report_Data = table_data[0] # ---> [1] 일 경우는 하단의 페이지 번호가 출력\n",
    "        # print(Report_Data)\n",
    "        ahref_list = []\n",
    "        for x in table2 :\n",
    "            ahref = x.get('title')\n",
    "            ahref_list.append(ahref)\n",
    "        Report_Data['dates'] = ahref_list # 2021-02-26 21:29:55\n",
    "        Report_Data = Report_Data.drop(Report_Data[Report_Data['번호']=='AD'].index, axis=0)\n",
    "        Report_Data = Report_Data.drop(Report_Data[Report_Data['번호']=='공지'].index, axis=0)\n",
    "        Report_Data['dates'] = pd.to_datetime(Report_Data['dates'], format='%Y-%m-%d %H:%M:%S') # 2021-02-26 21:29:55\n",
    "        Report_Data['new_dates'] = Report_Data['dates'].dt.strftime('%Y.%m.%d')\n",
    "\n",
    "        # Table_DF = Table_DF.append(Report_Data['new_dates'])\n",
    "        Table_DF = Table_DF.append(Report_Data)\n",
    "\n",
    "        # time.sleep(1) # urllib.error.URLError: <urlopen error [Errno 60] Operation timed out>\n",
    "\n",
    "    Group_DC = Table_DF.groupby('new_dates').count()\n",
    "    # print(\"# Group_Action_Table : \")\n",
    "    # print(Group_DC['번호'])\n",
    "    # output = open(\"DC_index.txt\", 'w+t')\n",
    "    # output.write(Group_DC)\n",
    "    # Group_DC['번호'].to_csv(\"DC_index.txt\")\n",
    "    Report_DC = pd.DataFrame(Group_DC['번호'])\n",
    "\n",
    "    return Report_DC\n",
    "\n",
    "def __CL_Last_Page_Find(page) :\n",
    "\n",
    "    print(\"# Clien Function Start\")\n",
    "    Table_DF = pd.DataFrame()\n",
    "\n",
    "    for page_num in range(0,page) :\n",
    "    # for page_num in range(0,2) :\n",
    "        sleep_count = page_num % 10\n",
    "        if sleep_count == 0 :\n",
    "            print(\"# Sleep Time : 10s\")\n",
    "            print(\"# Sleep Count : %s\" % sleep_count)\n",
    "            time.sleep(10)\n",
    "\n",
    "        url = \"https://www.clien.net/service/board/cm_stock?&od=T31&po=\" + str(page_num) # Stock\n",
    "        # url = \"https://www.clien.net/service/board/cm_vcoin?&od=T31&po=\" + str(page_num) # Coin\n",
    "        print(url)\n",
    "\n",
    "        req = Request(url=url, headers=headers)\n",
    "\n",
    "        try :\n",
    "            html = urlopen(req).read()\n",
    "            # html = urlopen(url, context=context)\n",
    "        except HTTPError as err:\n",
    "            if err.code == 404 :\n",
    "                print(\"# Error HTTP : 404\")\n",
    "                return\n",
    "            elif err.code == 403 :\n",
    "                print(\"# Error HTTP : 403\")\n",
    "                return\n",
    "            elif err.code == 500 :\n",
    "                print(\"# Error HTTP : 500\")\n",
    "                return\n",
    "            elif err.code == 505:\n",
    "                print(\"# Error HTTP : 505\")\n",
    "                return\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "        # print(bs_object)\n",
    "        table = bs_object.find_all(\"span\", {'class' : 'timestamp'})\n",
    "        # print(type(table))\n",
    "        # print(table)\n",
    "        date_list = []\n",
    "        for x in table :\n",
    "            # print(type(x.text))\n",
    "            if x.text != '2014-10-24 15:46:09' and x.text != '2020-03-27 15:14:21' \\\n",
    "                and x.text != '2021-02-26 17:12:17' and x.text != '2021-01-21 12:46:02' and x.text != '2020-07-22 21:37:38' :\n",
    "                # print(x.text)\n",
    "                date_list.append(x.text)\n",
    "\n",
    "        Report_Data = pd.DataFrame({'dates' : date_list})\n",
    "        Report_Data['dates'] = pd.to_datetime(Report_Data['dates'], format='%Y-%m-%d %H:%M:%S') # 2021-02-26 21:29:55\n",
    "        Report_Data['new_dates'] = Report_Data['dates'].dt.strftime('%Y.%m.%d')\n",
    "        # print(Report_Data)\n",
    "        # Report_Data['Count'] = '1'\n",
    "        Group_CL = Report_Data.groupby('new_dates').count()\n",
    "        # print(Group_CL)\n",
    "\n",
    "        # Report_Data['dates'] = pd.to_datetime(Report_Data['dates'], format='%Y-%m-%d %H:%M:%S') # 2021-02-26 21:29:55\n",
    "        # Report_Data['new_dates'] = Report_Data['dates'].dt.strftime('%Y.%m.%d')\n",
    "\n",
    "        Table_DF = Table_DF.append(Group_CL)\n",
    "\n",
    "        time.sleep(2) # urllib.error.URLError: <urlopen error [Errno 60] Operation timed out>\n",
    "\n",
    "    Table_DF = Table_DF.groupby('new_dates').sum()\n",
    "\n",
    "    return Table_DF\n",
    "\n",
    "def __New_Make_Chart (Market_1, Market_2, Date_List, Market_List, Count_List) :\n",
    "    # __New_Make_Chart (\"KOSPI\", \"DC_Inside\", Date_List, Market_List, Count_List)\n",
    "\n",
    "    DateTime = datetime.datetime.today().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "    print(\"# Platform : %s\" % platform.system())\n",
    "\n",
    "    if platform.system() == 'Darwin' :\n",
    "        File_Name = \"/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/\"+Market_1+\"_\"+Market_2+\"_\"+DateTime+\".html\"\n",
    "        input_1 = open('/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/New_Echart_Test_1.html', 'r') # Echrt의 머릿글\n",
    "    else :\n",
    "        File_Name = \"D:\\\\Python\\\\Log\\\\\"+Market_1+\"_\"+Market_2+\"_\"+DateTime+\".html\"\n",
    "        input_1 = open('D:\\\\Python\\\\Log\\\\New_Echart_Test_1.html', 'r') # Echrt의 머릿글\n",
    "\n",
    "    closing_list_A = Market_List\n",
    "    closing_list_B = Count_List\n",
    "    date_list = Date_List\n",
    "\n",
    "    if len(date_list) > 400 :\n",
    "        n = 400\n",
    "    else :\n",
    "        n = len(date_list)\n",
    "        \n",
    "    print(\"date list 0 : %s\" % date_list[0])\n",
    "    print(\"date leng : %s\" % len(date_list))\n",
    "    del date_list[n:]\n",
    "    del Market_List[n:]\n",
    "    del Count_List[n:]\n",
    "    print(\"# After DEL\")\n",
    "    print(\"date list 0 : %s\" % date_list[0])\n",
    "    print(\"date leng : %s\" % len(date_list))\n",
    "\n",
    "    output = open(File_Name, 'w+t')\n",
    "    output.write('<head><meta charset=\"utf-8\"></head>')\n",
    "\n",
    "    # for idx, val in enumerate(closing_list_A) :\n",
    "    #     if type(closing_list_A[idx]) == int or type(closing_list_A[idx]) == float :\n",
    "    #         continue\n",
    "    #     else :\n",
    "    #         closing_list_A[idx] = val\n",
    "\n",
    "    numrow_A = [float(x) for x in closing_list_A]\n",
    "    max_value_A = int(max(numrow_A)) * 1.5\n",
    "    numrow_B = [float(x) for x in closing_list_B]\n",
    "    max_value_B = int(max(numrow_B)) * 1.5 # ---> ValueError: could not convert string to float: '11,550'\n",
    "\n",
    "    print(\"# MAKE HTML Start\")\n",
    "    for line in input_1.readlines():\n",
    "        output.write(line)\n",
    "    output.write(\"        data: ['%s', '%s']\\n\" % (Market_1, Market_2))\n",
    "    output.write(\"    },\\n\")\n",
    "    output.write(\"    xAxis: [\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            type: 'category',\\n\")\n",
    "    output.write(\"            axisTick: {\\n\")\n",
    "    output.write(\"                alignWithLabel: true\\n\")\n",
    "    output.write(\"            },\\n\")\n",
    "    output.write(\"            data: [\")\n",
    "    # for item in date_list[::-1] :\n",
    "    for item in date_list :\n",
    "        output.write(\"'%s',\" % item)\n",
    "    output.write(\"        ]\\n\")\n",
    "    output.write(\"        }\\n\")\n",
    "    output.write(\"    ],\\n\")\n",
    "    output.write(\"    yAxis: [\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            type: 'value',\\n\")\n",
    "    output.write(\"            name: '%s',\\n\" % Market_1)\n",
    "    output.write(\"            min: 0,\\n\")\n",
    "    output.write(\"            max: %s,\\n\" % str(max_value_A))\n",
    "    output.write(\"            position: 'right',\\n\")\n",
    "    output.write(\"            axisLine: {\\n\")\n",
    "    output.write(\"                lineStyle: {\\n\")\n",
    "    output.write(\"                    color: colors[0]\\n\")\n",
    "    output.write(\"                }\\n\")\n",
    "    output.write(\"            },\\n\")\n",
    "    output.write(\"            axisLabel: {\\n\")\n",
    "    output.write(\"                formatter: '{value} pt'\\n\")\n",
    "    output.write(\"            }\\n\")\n",
    "    output.write(\"        },\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            type: 'value',\\n\")\n",
    "    output.write(\"            name: '%s',\\n\" % Market_2)\n",
    "    output.write(\"            min: 0,\\n\")\n",
    "    output.write(\"            max: %s,\\n\" % str(max_value_B))\n",
    "    output.write(\"            position: 'left',\\n\")\n",
    "    output.write(\"            axisLine: {\\n\")\n",
    "    output.write(\"                lineStyle: {\\n\")\n",
    "    output.write(\"                    color: colors[1]\\n\")\n",
    "    output.write(\"                }\\n\")\n",
    "    output.write(\"            },\\n\")\n",
    "    output.write(\"            axisLabel: {\\n\")\n",
    "    output.write(\"                formatter: '{value} pt'\\n\")\n",
    "    output.write(\"            }\\n\")\n",
    "    output.write(\"        }\\n\")\n",
    "    output.write(\"    ],\\n\")\n",
    "    output.write(\"    series: [\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            name: '%s',\\n\" % Market_1)\n",
    "    output.write(\"            type: 'line',\\n\")\n",
    "    output.write(\"              data: [\\n\")\n",
    "    # for x in closing_list_A[::-1] :\n",
    "    for x in closing_list_A :\n",
    "        output.write(\"'%s',\" % x)\n",
    "    output.write(\"        ]\\n\")\n",
    "    output.write(\"        },\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            name: '%s',\\n\" % Market_2)\n",
    "    output.write(\"            type: 'line',\\n\")\n",
    "    output.write(\"            yAxisIndex: 1,\\n\")\n",
    "    output.write(\"              data: [\\n\")\n",
    "    # for x in closing_list_B[::-1]  :\n",
    "    for x in closing_list_B :\n",
    "        output.write(\"'%s',\" % x)\n",
    "    output.write(\"    ]\\n\")\n",
    "    output.write(\"        }\\n\")\n",
    "    output.write(\"    ]\\n\")\n",
    "    output.write(\"};\\n\")\n",
    "    output.write(\"        // use configuration item and data specified to show chart\\n\")\n",
    "    output.write(\"        myChart.setOption(option);\\n\")\n",
    "    output.write(\"    </script>\\n\")\n",
    "    output.write(\"</body>\\n\")\n",
    "\n",
    "    # for line in input_2.readlines():\n",
    "        # output.write(line)\n",
    "\n",
    "    print(\"# MAKE HTML Done\")\n",
    "\n",
    "    output.close()\n",
    "\n",
    "if(__name__ == '__main__') :\n",
    "    print(\"# Program Start\")\n",
    "\n",
    "    Main_DF = pd.DataFrame()\n",
    "\n",
    "    KOSPI_Page = __Last_Page_Numb_Market(\"KOSPI\") # ---> 최근 1년이면 굳이 모두 할 필요없다.\n",
    "    KOSPI_Date, KOSPI_List = __Market_Price(\"KOSPI\", KOSPI_Page)\n",
    "    KOSPI = pd.DataFrame({'new_dates' : KOSPI_Date, 'kospi': KOSPI_List})\n",
    "    print(KOSPI)\n",
    "    KOSPI.to_csv(\"KOSPI.txt\")\n",
    "\n",
    "    KOSDAQ_Page = __Last_Page_Numb_Market(\"KOSDAQ\") # ---> 최근 1년이면 굳이 모두 할 필요없다.\n",
    "    KOSDAQ_Date, KOSDAQ_List = __Market_Price(\"KOSDAQ\", KOSDAQ_Page)\n",
    "    KOSDAQ = pd.DataFrame({'date' : KOSDAQ_Date, 'kosdaq': KOSDAQ_List})\n",
    "    print(KOSDAQ)\n",
    "    KOSDAQ.to_csv(\"KOSDAQ.txt\")\n",
    "\n",
    "    DC_Check = 0\n",
    "    CL_Check = 1\n",
    "\n",
    "    if CL_Check == 1 :\n",
    "        DateTime = datetime.datetime.today().strftime(\"%Y%m%d\")\n",
    "        # CL_page = 1335 # 2021.05.21\n",
    "        CL_page = 500\n",
    "        # Coin_page = 2716\n",
    "\n",
    "        CL_Action_Table = __CL_Last_Page_Find(CL_page)\n",
    "        # CL_Action_Table = __CL_Last_Page_Find(Coin_page)\n",
    "        print(\"# CL\")\n",
    "        print(CL_Action_Table)\n",
    "        CL_Action_Table.to_csv(\"CL_Action_Table\"+DateTime+\".txt\")\n",
    "\n",
    "        ############################################################\n",
    "        # Clien & KOSPI\n",
    "        KOSPI_CL = CL_Action_Table.join(KOSPI.set_index('new_dates'), on='new_dates')\n",
    "        KOSPI_CL.dropna(subset=['kospi'], inplace=True)\n",
    "        print(\"# KOSPI_CL\")\n",
    "        print(KOSPI_CL)\n",
    "        KOSPI_CL = KOSPI_CL.reset_index()\n",
    "        print(\"# KOSPI_CL 3\")\n",
    "        print(KOSPI_CL)\n",
    "        Date_List = KOSPI_CL['new_dates'].to_list()\n",
    "        Market_List = KOSPI_CL['kospi'].to_list()\n",
    "        Count_List = KOSPI_CL['dates'].to_list()\n",
    "        __New_Make_Chart (\"KOSPI\", \"Clien\", Date_List, Market_List, Count_List)\n",
    "\n",
    "        ############################################################\n",
    "        # Clien & KOSDAQ\n",
    "        print(\"# KOSDAQ\")\n",
    "        print(KOSDAQ)\n",
    "        KOSDAQ.rename(columns={'date': 'new_dates'}, inplace = True)\n",
    "        KOSDAQ_CL = CL_Action_Table.join(KOSDAQ.set_index('new_dates'), on='new_dates')\n",
    "        KOSDAQ_CL.dropna(subset=['kosdaq'], inplace=True)\n",
    "        print(\"# KOSDAQ_CL\")\n",
    "        print(KOSDAQ_CL)\n",
    "        KOSDAQ_CL = KOSDAQ_CL.reset_index()\n",
    "        print(\"# KOSDAQ_CL 3\")\n",
    "        print(KOSDAQ_CL)\n",
    "        Date_List = KOSDAQ_CL['new_dates'].to_list()\n",
    "        Market_List = KOSDAQ_CL['kosdaq'].to_list()\n",
    "        Count_List = KOSDAQ_CL['dates'].to_list()\n",
    "        __New_Make_Chart (\"KOSDAQ\", \"Clien\", Date_List, Market_List, Count_List)\n",
    "\n",
    "    if DC_Check == 1 :\n",
    "        DateTime = datetime.datetime.today().strftime(\"%Y%m%d\")\n",
    "        # DC_page = 11779\n",
    "        # DC_page = 10000\n",
    "        DC_page = 500\n",
    "\n",
    "        DC_Action_Table = __DC_Last_Page_Find(DC_page)\n",
    "        print(\"# DC\")\n",
    "        print(DC_Action_Table)\n",
    "        DC_Action_Table.to_csv(\"DC_Action_Table\"+DateTime+\".txt\")\n",
    "\n",
    "        ############################################################\n",
    "        # DC & KOSPI\n",
    "        KOSPI_DC = DC_Action_Table.join(KOSPI.set_index('new_dates'), on='new_dates')\n",
    "        print(\"# KOSPI_DC 1\")\n",
    "        print(KOSPI_DC)\n",
    "        KOSPI_DC.dropna(subset=['kospi'], inplace=True) \n",
    "        print(\"# KOSPI_DC 2\")\n",
    "        print(KOSPI_DC)\n",
    "        KOSPI_DC = KOSPI_DC.reset_index()\n",
    "        print(\"# KOSPI_DC 3\")\n",
    "        print(KOSPI_DC)\n",
    "        Date_List = KOSPI_DC['new_dates'].to_list()\n",
    "        Market_List = KOSPI_DC['kospi'].to_list()\n",
    "        Count_List = KOSPI_DC['번호'].to_list()\n",
    "\n",
    "        __New_Make_Chart (\"KOSPI\", \"DC_Inside\", Date_List, Market_List, Count_List)\n",
    "\n",
    "        ###########################################################\n",
    "        # DC & KOSDAQ\n",
    "        KOSDAQ_DC = DC_Action_Table.join(KOSDAQ.set_index('new_dates'), on='new_dates')\n",
    "        print(\"# KOSDAQ_DC 1\")\n",
    "        print(KOSDAQ_DC)\n",
    "        KOSDAQ_DC.dropna(subset=['kosdaq'], inplace=True) \n",
    "        print(\"# KOSDAQ_DC 2\")\n",
    "        print(KOSDAQ_DC)\n",
    "        KOSDAQ_DC = KOSDAQ_DC.reset_index()\n",
    "        print(\"# KOSDAQ_DC 3\")\n",
    "        print(KOSDAQ_DC)\n",
    "        Date_List = KOSDAQ_DC['new_dates'].to_list()\n",
    "        Market_List = KOSDAQ_DC['kosdaq'].to_list()\n",
    "        Count_List = KOSDAQ_DC['번호'].to_list()\n",
    "\n",
    "        __New_Make_Chart (\"KOSDAQ\", \"DC_Inside\", Date_List, Market_List, Count_List)\n",
    "\n",
    "    print(\"# Value_Find for STATEMENTS End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
