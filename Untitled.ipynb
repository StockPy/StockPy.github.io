{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "# Program Start\n",
      "############################################################\n",
      "############################################################\n",
      "# ROE_Min = 20\n",
      "# PER_Min, PER_Max = 1, 20\n",
      "############################################################\n",
      "# FOR Loop Start\n",
      "# Market : 1\n",
      "# Main_DF_Result : Sorting ROE...\n",
      "# Main_DF_Result : Sorting ROE then Condition with ROE_Min...\n",
      "# FOR Loop End\n",
      "# FOR Loop Start\n",
      "# Market : 2\n",
      "# Main_DF_Result : Sorting ROE...\n",
      "# Main_DF_Result : Sorting ROE then Condition with ROE_Min...\n",
      "# FOR Loop End\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CORPCODE.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cbb562a05902>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   1829\u001b[0m         \u001b[1;31m# print(Result_Comp)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1831\u001b[1;33m     \u001b[0mCorp_DF\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0m__get_XML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1832\u001b[0m     \u001b[1;31m# print(Corp_DF[Corp_DF['corp_name']==\"삼성전자\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1833\u001b[0m     \u001b[1;31m# print(Corp_DF[Corp_DF['corp_name']==\"삼성전자\"].values)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-cbb562a05902>\u001b[0m in \u001b[0;36m__get_XML\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m__get_XML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mxtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0met\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CORPCODE.xml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mxroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\xml\\etree\\ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(source, parser)\u001b[0m\n\u001b[0;32m   1195\u001b[0m     \"\"\"\n\u001b[0;32m   1196\u001b[0m     \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1197\u001b[1;33m     \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1198\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\xml\\etree\\ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, source, parser)\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[0mclose_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m             \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m             \u001b[0mclose_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CORPCODE.xml'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.error import HTTPError\n",
    "from urllib.parse import quote\n",
    "from matplotlib import pyplot as plt\n",
    "import bs4, ssl\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime, time # for sleep\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "import xml.etree.ElementTree as et \n",
    "\n",
    "import json\n",
    "import urllib\n",
    "import urllib.request\n",
    "import sys\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                            'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                            'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "            'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "            'Accept-Encoding': 'none', \\\n",
    "            'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "            'Connection': 'keep-alive'}\n",
    "############################################################\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "API_KEY='0fcb8ef56cf8e8b996d47937a8fea5aba8c8d1be'\n",
    "\n",
    "############################################################\n",
    "\n",
    "def __get_XML():\n",
    "\n",
    "    xtree = et.parse(\"CORPCODE.xml\")\n",
    "    xroot = xtree.getroot() \n",
    "\n",
    "    df_cols = [\"corp_code\", \"corp_name\", \"stock_code\", \"modify_date\"]\n",
    "    rows = []\n",
    "\n",
    "    for node in xroot: \n",
    "        # s_name = node.attrib.get(\"corp_code\")\n",
    "        s_name = node.find(\"corp_code\").text if node is not None else None\n",
    "        s_mail = node.find(\"corp_name\").text if node is not None else None\n",
    "        s_grade = node.find(\"stock_code\").text if node is not None else None\n",
    "        s_age = node.find(\"modify_date\").text if node is not None else None\n",
    "        \n",
    "        rows.append({\"corp_code\": s_name, \"corp_name\": s_mail, \"stock_code\": s_grade, \"modify_date\": s_age})\n",
    "\n",
    "    pd.set_option('display.max_rows', 500)\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    pd.set_option('display.width', 1000)\n",
    "\n",
    "    Corp_DF = pd.DataFrame(rows, columns = df_cols)\n",
    "    # Corp_DF = Corp_DF.dropna(inplace=True)\n",
    "    # Corp_DF.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)\n",
    "    # Corp_DF.drop(labels=['stock_code'], axis=0, index=None, columns=None, level=None, inplace=True, errors='raise')\n",
    "    Corp_DF = Corp_DF.drop(Corp_DF[Corp_DF['stock_code']==' '].index, axis=0)\n",
    "    # print(Corp_DF.columns)\n",
    "    # print(Corp_DF.values)\n",
    "    # print(Corp_DF)\n",
    "\n",
    "    return Corp_DF\n",
    "\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "def __Last_Page_Find(i, Market) :\n",
    "    # print(\"# Last_Page_Find Start\")\n",
    "    if Market == 1 :\n",
    "        url = \"https://finance.naver.com/sise/sise_market_sum.nhn?&page=\" + str(i)\n",
    "    else :\n",
    "        url = \"https://finance.naver.com/sise/sise_market_sum.nhn?sosok=1&page=\" + str(i)\n",
    "    # print(\"# print URL\")\n",
    "    # print(url) # ---> 당시의 위치정보를 기반으로 15페이지 가져오는 듯, 어찌 가져오는지는 모르겠음...(2020.05.21)\n",
    "    # ---> HTTP Error 403: Forbidden\n",
    "    # headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\n",
    "    # req = Request(url=url, headers={'User-Agent': 'Mozilla/5.0', 'referer': 'http://m.naver.com'})\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                             'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                             'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "               'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "               'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "               'Accept-Encoding': 'none', \\\n",
    "               'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "               'Connection': 'keep-alive'}\n",
    "    req = Request(url=url, headers=headers)\n",
    "\n",
    "    try :\n",
    "        html = urlopen(req).read()\n",
    "        # html = urlopen(url, context=context)\n",
    "    except HTTPError as err:\n",
    "        if err.code == 404 :\n",
    "            print(\"# Error HTTP : 404\")\n",
    "            return\n",
    "        elif err.code == 403 :\n",
    "            print(\"# Error HTTP : 403\")\n",
    "            return\n",
    "        elif err.code == 500 :\n",
    "            print(\"# Error HTTP : 500\")\n",
    "            return\n",
    "        elif err.code == 505:\n",
    "            print(\"# Error HTTP : 505\")\n",
    "            return\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    # test = bs_object.find('table' ,attrs={'class':'type_2'})\n",
    "    # numbersss = test.findAll(\"td\", {\"class\": \"number\"})\n",
    "    # print(numbersss)\n",
    "\n",
    "    data = []\n",
    "    table = bs_object.find('table', attrs={'class':'type_2'})\n",
    "    table_body = table.find('tbody')\n",
    "    rows = table_body.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "    # print(\"##################\")\n",
    "    # for x in data :\n",
    "        # print(x)\n",
    "\n",
    "    # print(\"##########################################\")\n",
    "    # print(type(data))\n",
    "    Data_DF = pd.DataFrame(data, columns=['No','회사명','현재가','전일비','등락률','액면가','시가총액','상장주식수','외국인비율','거래량','PER','ROE'])\n",
    "    # print(type(data_df))\n",
    "    # print(data_df)\n",
    "    # print(\"# Drop NA\")\n",
    "    Data_DF = Data_DF.dropna()\n",
    "    Data_DF = Data_DF[['No','회사명','ROE','PER','외국인비율']]\n",
    "    if Market == 1 :\n",
    "        Data_DF['Market'] = \"코스피\"\n",
    "    else :\n",
    "        Data_DF['Market'] = \"코스닥\"\n",
    "    # print(\"# Data_DF.LOC\")\n",
    "    # print(Data_DF.loc['PER':'ROE'])\n",
    "    # print(\"# Data_DF.iLOC\")\n",
    "    # print(Data_DF.iloc[0:1])\n",
    "    # print(\"# Data_DF\")\n",
    "    # print(Data_DF)\n",
    "\n",
    "    return Data_DF\n",
    "\n",
    "############################################################\n",
    "# 10 페이지를 조회하여 결과 값 전달 (50기업 * 10페이지 = 500개 기업)\n",
    "############################################################\n",
    "def __Get_Result(Market, ROE_Min) :\n",
    "    Main_DF = pd.DataFrame()\n",
    "    print(\"# FOR Loop Start\")\n",
    "    print(\"# Market : %s\" % Market)\n",
    "    for i in range(1,11) : # 10 페이지 조회, 1페이지 당 50개, 총 500개???\n",
    "        Data_DF = __Last_Page_Find(i, Market)\n",
    "        Main_DF = Main_DF.append(Data_DF)\n",
    "        # time.sleep(1)\n",
    "\n",
    "    # 아래와 같이 종목코드를 별도로 뽑으려 했으나 Get_XML로 조치\n",
    "    # df_expcode = pd.read_html('http://kind.krx.co.kr/corpgeneral/corpList.do?method=download', header=0)[0]\n",
    "    # df_expcode = df_expcode[['회사명','종목코드']]\n",
    "    # Main_DF_Result = Main_DF.join(df_expcode.set_index('회사명'), on='회사명')\n",
    "\n",
    "    # print(\"DROP NA\")\n",
    "    # print(Main_DF)\n",
    "\n",
    "    Main_DF_Result = Main_DF\n",
    "    # Main_DF_Result = Main_DF_Result.drop(Main_DF_Result[Main_DF_Result['ROE']=='N/A'].index)\n",
    "    # Main_DF_Result = Main_DF_Result.drop(Main_DF_Result[Main_DF_Result['ROE']=='NaN'].index)\n",
    "    # Main_DF_Result = Main_DF_Result.drop(Main_DF_Result[Main_DF_Result['PER']=='NaN'].index)\n",
    "    # ---> 잘먹지도 않고 엉뚱한 값들이 없어짐\n",
    "    # Main_DF_Result.ROE = Main_DF_Result.ROE.astype(float)\n",
    "    # ---> ValueError: could not convert string to float: '-1,695.71'\n",
    "    Main_DF_Result.dropna(inplace=True)\n",
    "    Main_DF_Result.ROE = pd.to_numeric(Main_DF_Result.ROE, errors='coerce')\n",
    "    Main_DF_Result.PER = pd.to_numeric(Main_DF_Result.PER, errors='coerce')\n",
    "    \n",
    "    # print(\"# Sorting ROE\")\n",
    "    # Main_DF_Result = Main_DF_Result.sort_values('ROE')\n",
    "    Main_DF_Result = Main_DF_Result.sort_values(by=['ROE'], ascending=False)\n",
    "    print(\"# Main_DF_Result : Sorting ROE...\")\n",
    "    # print(Main_DF_Result)\n",
    "\n",
    "    # print(\"######################################\")\n",
    "    # print(Main_DF_Result.shape())\n",
    "    # print(Main_DF_Result.shape[0])\n",
    "    # print(Main_DF_Result.shape[1])\n",
    "    # print(Main_DF_Result.loc[(Main_DF_Result['PER'] < 20)].shape[0])\n",
    "    # print(Main_DF_Result.loc[(Main_DF_Result['PER'] > 20)].shape[0])\n",
    "    # print(Main_DF_Result.loc[(Main_DF_Result['PER'] > 0)& (Main_DF_Result['PER'] < 16)].shape[0])\n",
    "    # print(Main_DF_Result.loc[(Main_DF_Result['PER'] > 0)& (Main_DF_Result['PER'] < 16)].head(10))\n",
    "    # print(Main_DF_Result.loc[(Main_DF_Result['PER'] > 0)& (Main_DF_Result['PER'] < 16)])\n",
    "    # print(\"Top 10\")\n",
    "    # Get_Comp = Main_DF_Result.loc[(Main_DF_Result['PER'] > 0)& (Main_DF_Result['PER'] < 16)].head(10)\n",
    "    print(\"# Main_DF_Result : Sorting ROE then Condition with ROE_Min...\")\n",
    "    Get_Comp = Main_DF_Result.loc[(Main_DF_Result['ROE'] > ROE_Min)]\n",
    "    Get_Comp = Main_DF_Result.loc[(Main_DF_Result['PER'] > 0)]\n",
    "    # print(Get_Comp)\n",
    "\n",
    "    print(\"# FOR Loop End\")\n",
    "\n",
    "    return Get_Comp\n",
    "\n",
    "def __Naver_CompInfo(Dart_Corp_Code, Dart_Exp_Code, File_Name) :\n",
    "\n",
    "    print(File_Name)\n",
    "    output = open(File_Name, 'a+t')\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    print(\"# Dart_Naver_CompInfo Start\")\n",
    "    output.write(\"# Dart_Naver_CompInfo Start\\n\")\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    print(\"\")\n",
    "    output.write(\"\\n\")\n",
    "    url = \"https://finance.naver.com/item/coinfo.nhn?code=\" + Dart_Exp_Code\n",
    "    output.write(\"%s \\n\" % url) # ---> 당시의 위치정보를 기반으로 15페이지 가져오는 듯, 어찌 가져오는지는 모르겠음...(2020.05.21)\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                             'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                             'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "               'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "               'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "               'Accept-Encoding': 'none', \\\n",
    "               'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "               'Connection': 'keep-alive'}\n",
    "    req = Request(url=url, headers=headers)\n",
    "\n",
    "    try :\n",
    "        html = urlopen(req).read()\n",
    "        # html = urlopen(url, context=context)\n",
    "    except HTTPError as err:\n",
    "        if err.code == 404 :\n",
    "            print(\"# Error HTTP : 404\")\n",
    "            return\n",
    "        elif err.code == 403 :\n",
    "            print(\"# Error HTTP : 403\")\n",
    "            return\n",
    "        elif err.code == 500 :\n",
    "            print(\"# Error HTTP : 500\")\n",
    "            return\n",
    "        elif err.code == 505:\n",
    "            print(\"# Error HTTP : 505\")\n",
    "            return\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    table = bs_object.find('div', {'id':'summary_info'})\n",
    "    table_body = table.find_all('p')\n",
    "\n",
    "    # print(table_body)\n",
    "    for x in table_body :\n",
    "        print(x.get_text())\n",
    "        output.write(\"%s \\n\" % x.get_text())\n",
    "    print(\"\")\n",
    "\n",
    "    output.write(\"\\n\")\n",
    "    output.close()\n",
    "\n",
    "def __Naver_BusinessType(Dart_Exp_Code, File_Name) :\n",
    "\n",
    "    output = open(File_Name, 'a+t')\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    print(\"# 동종 업계 비교\")\n",
    "    output.write(\"# 동종 업계 비교\\n\")\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "\n",
    "    url = \"https://finance.naver.com/item/main.nhn?code=\" + Dart_Exp_Code\n",
    "    output.write(\"%s \\n\" % url)\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                             'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                             'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "               'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "               'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "               'Accept-Encoding': 'none', \\\n",
    "               'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "               'Connection': 'keep-alive'}\n",
    "    req = Request(url=url, headers=headers)\n",
    "\n",
    "    try :\n",
    "        html = urlopen(req).read()\n",
    "        # html = urlopen(url, context=context)\n",
    "    except HTTPError as err:\n",
    "        if err.code == 404 :\n",
    "            print(\"# Error HTTP : 404\")\n",
    "            return\n",
    "        elif err.code == 403 :\n",
    "            print(\"# Error HTTP : 403\")\n",
    "            return\n",
    "        elif err.code == 500 :\n",
    "            print(\"# Error HTTP : 500\")\n",
    "            return\n",
    "        elif err.code == 505:\n",
    "            print(\"# Error HTTP : 505\")\n",
    "            return\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    table = bs_object.find('div', {'class':'section trade_compare'})\n",
    "    table_data = pd.read_html(str(table))\n",
    "    print(table_data)\n",
    "    # PBR_Raw = table_data[0]\n",
    "    # print(PBR_Raw.columns)\n",
    "    # print(PBR_Raw.values)\n",
    "    output.write(\"%s\\n\" % table_data)\n",
    "    output.write(\"\\n\")\n",
    "\n",
    "    output.close()\n",
    "\n",
    "def __Naver_Inst_Anal(Dart_Exp_Code) :\n",
    "\n",
    "    # print(\"############################################################\")\n",
    "    # print(\"# Naver 투자 지표\")\n",
    "    # print(\"############################################################\")\n",
    "\n",
    "    url = \"https://navercomp.wisereport.co.kr/v2/company/c1040001.aspx?cmp_cd=\" + Dart_Exp_Code\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                             'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                             'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "               'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "               'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "               'Accept-Encoding': 'none', \\\n",
    "               'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "               'Connection': 'keep-alive'}\n",
    "    req = Request(url=url, headers=headers)\n",
    "\n",
    "    try :\n",
    "        html = urlopen(req).read()\n",
    "        # html = urlopen(url, context=context)\n",
    "    except HTTPError as err:\n",
    "        if err.code == 404 :\n",
    "            print(\"# Error HTTP : 404\")\n",
    "            return\n",
    "        elif err.code == 403 :\n",
    "            print(\"# Error HTTP : 403\")\n",
    "            return\n",
    "        elif err.code == 500 :\n",
    "            print(\"# Error HTTP : 500\")\n",
    "            return\n",
    "        elif err.code == 505:\n",
    "            print(\"# Error HTTP : 505\")\n",
    "            return\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    # print(bs_object)\n",
    "    # table_anal = bs_object.find('table', {'class':'gHead01 all-width data-list'})\n",
    "    # table_anal = bs_object.find('div', {'class':'tcRVArcVR1a2'})\n",
    "    table_anal = bs_object.find('td', {'class':'cmp-table-cell td0301'})\n",
    "    # print(table_anal.text) # ---> <class 'str'>\n",
    "\n",
    "    str_anal = \"\"\n",
    "    for find_text_list in table_anal.text :\n",
    "        if \"\\n\" not in find_text_list :\n",
    "            # print(find_text_list, end=\"\")\n",
    "            str_anal += find_text_list\n",
    "        else :\n",
    "            str_anal += \"\\n\"\n",
    "    # print(str_anal.splitlines()) # ---> ['', '', 'EPS 3,014', 'BPS 14,640', 'PER 19.01', '업종PER N/A', 'PBR 3.91', '현금배당수익률 0.87%', '12월 결산', '']\n",
    "    str_anal_DF = pd.DataFrame([x.split(';') for x in str_anal.split('\\n')])\n",
    "    str_anal_DF.dropna()\n",
    "\n",
    "    return str_anal_DF.iloc[6].values[0]\n",
    "\n",
    "def __Naver_Anal(Dart_Exp_Code, File_Name) :\n",
    "\n",
    "    output = open(File_Name, 'a+t')\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    print(\"# 실적 동향\")\n",
    "    output.write(\"# 실적 동향\\n\")\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "\n",
    "    url = \"https://finance.naver.com/item/main.nhn?code=\" + Dart_Exp_Code\n",
    "    output.write(\"%s \\n\" % url)\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                             'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                             'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "               'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "               'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "               'Accept-Encoding': 'none', \\\n",
    "               'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "               'Connection': 'keep-alive'}\n",
    "    req = Request(url=url, headers=headers)\n",
    "\n",
    "    try :\n",
    "        html = urlopen(req).read()\n",
    "        # html = urlopen(url, context=context)\n",
    "    except HTTPError as err:\n",
    "        if err.code == 404 :\n",
    "            print(\"# Error HTTP : 404\")\n",
    "            return\n",
    "        elif err.code == 403 :\n",
    "            print(\"# Error HTTP : 403\")\n",
    "            return\n",
    "        elif err.code == 500 :\n",
    "            print(\"# Error HTTP : 500\")\n",
    "            return\n",
    "        elif err.code == 505:\n",
    "            print(\"# Error HTTP : 505\")\n",
    "            return\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    table_anal = bs_object.find('table', {'class':'tb_type1 tb_num tb_type1_ifrs'})\n",
    "    table_data_anal = pd.read_html(str(table_anal))\n",
    "\n",
    "    table_anal_DF = table_data_anal[0]\n",
    "    # print(table_anal_DF.columns)\n",
    "    # MultiIndex([(  '주요재무정보',     '주요재무정보', '주요재무정보'),\n",
    "    #         ('최근 연간 실적',    '2017.12', 'IFRS연결'),\n",
    "    #         ('최근 연간 실적',    '2018.12', 'IFRS연결'),\n",
    "    #         ('최근 연간 실적',    '2019.12', 'IFRS연결'),\n",
    "    #         ('최근 연간 실적', '2020.12(E)', 'IFRS연결'),\n",
    "    #         ('최근 분기 실적',    '2019.09', 'IFRS연결'),\n",
    "    #         ('최근 분기 실적',    '2019.12', 'IFRS연결'),\n",
    "    #         ('최근 분기 실적',    '2020.03', 'IFRS연결'),\n",
    "    #         ('최근 분기 실적',    '2020.06', 'IFRS연결'),\n",
    "    #         ('최근 분기 실적',    '2020.09', 'IFRS연결'),\n",
    "    #         ('최근 분기 실적', '2020.12(E)', 'IFRS연결')],\n",
    "    #        )\n",
    "    print(\"############################\")\n",
    "    print(table_anal_DF.columns)\n",
    "    print(\"############################\")\n",
    "    print(table_anal_DF.values)\n",
    "    print(\"############################\")\n",
    "    print(table_anal_DF)\n",
    "    print(\"############################\")\n",
    "\n",
    "    output.write(\"%s\\n\" % table_anal_DF)\n",
    "    output.write(\"\\n\")\n",
    "\n",
    "    output.close()\n",
    "\n",
    "def __Dart_Search_Code(Dart_Corp_Name, Dart_Exp_Code) :\n",
    "\n",
    "    import dart_fss as dart\n",
    "    from dart_fss import get_corp_list\n",
    "\n",
    "    BEGIN_DATE = \"20100101\"\n",
    "\n",
    "    # Open DART API KEY 설정\n",
    "    dart.set_api_key(api_key=API_KEY)\n",
    "\n",
    "    # DART 에 공시된 회사 리스트 불러오기\n",
    "    corp_list = dart.get_corp_list()\n",
    "\n",
    "    print(\"# Dart_Corp_Name : %s\" % Dart_Corp_Name)\n",
    "\n",
    "    Dart_DF = corp_list.find_by_corp_name(Dart_Corp_Name, exactly=True)[0]\n",
    "    # Dart_DF = corp_list.find_by_corp_name('삼성전자', exactly=True)[0]\n",
    "    # Dart_DF = corp_list.find_by_corp_name('삼성') # 삼성을 포함한 회사정보\n",
    "    # Dart_DF = corp_list.find_by_stock_code('005930') # Stock 코드로 찾기\n",
    "    # Dart_DF = corp_list.find_by_corp_code('00126380') # 다트에서 사용하는 회사코드를 이용한 찾기\n",
    "    # print(\"# Dart_DF\")\n",
    "    # print(Dart_DF)\n",
    "    print(\"\")\n",
    "\n",
    "def __Dart_Search_List(Dart_Corp_Code, Dart_Exp_Code, File_Name) :\n",
    "\n",
    "    output = open(File_Name, 'a+t')\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    print(\"# 공시보고 전체 리스트\")\n",
    "    output.write(\"# 공시보고 전체 리스트\\n\")\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "\n",
    "    BEGIN_Y_DATE = \"20100101\"\n",
    "    TODATE_Y_DATE = datetime.datetime.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                                'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                                'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "                'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "                'Accept-Encoding': 'none', \\\n",
    "                'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "                'Connection': 'keep-alive'}\n",
    "\n",
    "    # 공시 리스트 가져오기\n",
    "    url = \"http://opendart.fss.or.kr/api/list.json?crtfc_key=0fcb8ef56cf8e8b996d47937a8fea5aba8c8d1be&corp_code=\" \\\n",
    "         + Dart_Corp_Code + \"&bgn_de=\" + BEGIN_Y_DATE + \"&end_de=\" + TODATE_Y_DATE + \"&pblntf_ty=A&page_count=100\"\n",
    "    output.write(\"%s \\n\" % url)\n",
    "    req = Request(url=url, headers=headers)\n",
    "    html = urlopen(req).read()\n",
    "    html_output = html.decode('utf-8')\n",
    "    # print(\"# html_output\")\n",
    "    html_json = pd.read_json(html_output, encoding=\"utf-8\")\n",
    "    html_json = html_json.list.apply(pd.Series)\n",
    "    # print(html_json)\n",
    "    # print(type(html_json))\n",
    "    print(html_json[['report_nm', 'rcept_no', 'rcept_dt']])\n",
    "    output.write(\"%s \\n\" % html_json[['report_nm', 'rcept_no', 'rcept_dt']])\n",
    "    # html_json = json.dumps(html_json, ensure_ascii=False).encode('utf8')\n",
    "    # html_json = pd.json_normalize(html_json,'list')\n",
    "    # html_json = pd.json_normalize(html_json,'list', ['account_nm'],['thstrm_nm'],['thstrm_dt'],['thstrm_amount'],['frmtrm_nm'])\n",
    "    # print(html_json)\n",
    "    # py_json = son.loads(json_file.decode('utf-8'))\n",
    "    # python_df = pd_dataframe(py_json[\"key\"][0][\"key2\"], columns = ['col1', 'col2','col3','col4'])kk\n",
    "    print(\"\")\n",
    "    output.write(\"\\n\")\n",
    "\n",
    "    output.close()\n",
    "\n",
    "    return html_json[['rcept_no']].head(1)\n",
    "\n",
    "def __Dart_Search_1st(Dart_Corp_Code, Dart_Exp_Code, File_Name) :\n",
    "\n",
    "    output = open(File_Name, 'a+t')\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    print(\"# 최대주주 현황\")\n",
    "    output.write(\"# 최대주주 현황\\n\")\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "\n",
    "    BEGIN_Y_DATE = int(\"2015\")\n",
    "    TODATE_Y_DATE = int(datetime.datetime.today().strftime(\"%Y\"))+1\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                                'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                                'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "                'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "                'Accept-Encoding': 'none', \\\n",
    "                'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "                'Connection': 'keep-alive'}\n",
    "\n",
    "    for x in range(BEGIN_Y_DATE, TODATE_Y_DATE) :\n",
    "        url = \"http://opendart.fss.or.kr/api/hyslrSttus.json?crtfc_key=0fcb8ef56cf8e8b996d47937a8fea5aba8c8d1be&corp_code=\" \\\n",
    "            + Dart_Corp_Code + \"&bsns_year=\" + str(x) + \"&reprt_code=11011\"\n",
    "        output.write(\"%s \\n\" % url)\n",
    "        req = Request(url=url, headers=headers)\n",
    "        html = urlopen(req).read()\n",
    "        html_output = html.decode('utf-8')\n",
    "        print(\"# %s년 최대주주 현황\" % x)\n",
    "        output.write(\"# %s년 최대주주 현황\\n\" % x)\n",
    "        if \"013\" in html_output : # {\"status\":\"013\",\"message\":\"조회된 데이타가 없습니다.\"}\n",
    "            print(\"# ---> 조회 내역이 없음\")\n",
    "            output.write(\"# ---> 조회 내역이 없음\\n\")\n",
    "            continue\n",
    "        html_json = pd.read_json(html_output, encoding=\"utf-8\")\n",
    "        html_json = html_json.list.apply(pd.Series)\n",
    "        print(\"# 접수번호, 성명, 관계, 주식종류, 기초 소유 주식 지분율, 기말 소유 주식 지분율, 비고\")\n",
    "        print(html_json[['rcept_no', 'nm', 'relate', 'stock_knd', 'bsis_posesn_stock_qota_rt', 'trmend_posesn_stock_qota_rt', 'rm']])\n",
    "        output.write(\"%s \\n\" % html_json[['rcept_no', 'nm', 'relate', 'stock_knd', 'bsis_posesn_stock_qota_rt', 'trmend_posesn_stock_qota_rt', 'rm']])\n",
    "        print(\"\")\n",
    "\n",
    "    output.write(\"\\n\")\n",
    "    output.close()\n",
    "\n",
    "def __Dart_Search_1st_Diff(Dart_Corp_Code, Dart_Exp_Code, File_Name) :\n",
    "\n",
    "    output = open(File_Name, 'a+t')\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    print(\"# 최대 주주 변동 내역\")\n",
    "    output.write(\"# 최대 주주 변동 내역\\n\")\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "\n",
    "    BEGIN_Y_DATE = int(\"2015\")\n",
    "    TODATE_Y_DATE = int(datetime.datetime.today().strftime(\"%Y\"))+1\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                                'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                                'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "                'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "                'Accept-Encoding': 'none', \\\n",
    "                'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "                'Connection': 'keep-alive'}\n",
    "\n",
    "    for x in range(BEGIN_Y_DATE, TODATE_Y_DATE) :\n",
    "        url = \"http://opendart.fss.or.kr/api/hyslrChgSttus.json?crtfc_key=0fcb8ef56cf8e8b996d47937a8fea5aba8c8d1be&corp_code=\" \\\n",
    "            + Dart_Corp_Code + \"&bsns_year=\" + str(x) + \"&reprt_code=11011\"\n",
    "        output.write(\"%s \\n\" % url)\n",
    "        req = Request(url=url, headers=headers)\n",
    "        html = urlopen(req).read()\n",
    "        html_output = html.decode('utf-8')\n",
    "        print(\"# %s년 최대주주 변동 현황\" % x)\n",
    "        output.write(\"# %s년 최대주주 변동 현황\\n\" % x)\n",
    "        if \"013\" in html_output : # {\"status\":\"013\",\"message\":\"조회된 데이타가 없습니다.\"}\n",
    "            print(\"# ---> 조회 내역이 없음\")\n",
    "            output.write(\"# ---> 조회 내역이 없음\\n\")\n",
    "            continue\n",
    "        html_json = pd.read_json(html_output, encoding=\"utf-8\")\n",
    "        html_json = html_json.list.apply(pd.Series)\n",
    "        print(\"# 접수번호, 변동일, 최대주주명, 지분율, 변동원인, 비고\")\n",
    "        output.write(\"# 접수번호, 변동일, 최대주주명, 지분율, 변동원인, 비고\\n\")\n",
    "        print(html_json[['rcept_no', 'change_on', 'mxmm_shrholdr_nm', 'qota_rt', 'change_cause', 'rm']])\n",
    "        output.write(\"%s \\n\" % html_json[['rcept_no', 'change_on', 'mxmm_shrholdr_nm', 'qota_rt', 'change_cause', 'rm']])\n",
    "        print(\"\")\n",
    "\n",
    "    output.write(\"\\n\")\n",
    "    output.close()\n",
    "\n",
    "def __Dart_Search_Stock(Dart_Corp_Code, Dart_Exp_Code, File_Name) :\n",
    "\n",
    "    output = open(File_Name, 'a+t')\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    print(\"# 자기주식 취득 및 처분 현황\")\n",
    "    output.write(\"# 자기주식 취득 및 처분 현황\\n\")\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "\n",
    "    BEGIN_Y_DATE = int(\"2015\")\n",
    "    TODATE_Y_DATE = int(datetime.datetime.today().strftime(\"%Y\"))+1\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                                'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                                'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "                'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "                'Accept-Encoding': 'none', \\\n",
    "                'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "                'Connection': 'keep-alive'}\n",
    "\n",
    "    for x in range(BEGIN_Y_DATE, TODATE_Y_DATE) :\n",
    "        url = \"http://opendart.fss.or.kr/api/tesstkAcqsDspsSttus.json?crtfc_key=0fcb8ef56cf8e8b996d47937a8fea5aba8c8d1be&corp_code=\" \\\n",
    "            + Dart_Corp_Code + \"&bsns_year=\" + str(x) + \"&reprt_code=11011\"\n",
    "        output.write(\"%s \\n\" % url)\n",
    "        req = Request(url=url, headers=headers)\n",
    "        html = urlopen(req).read()\n",
    "        html_output = html.decode('utf-8')\n",
    "        print(\"# %s년 자기주식 취득 / 처분 현황\" % x)\n",
    "        output.write(\"# %s년 자기주식 취득 / 처분 현황\\n\" % x)\n",
    "        if \"013\" in html_output : # {\"status\":\"013\",\"message\":\"조회된 데이타가 없습니다.\"}\n",
    "            print(\"# ---> 조회 내역이 없음\")\n",
    "            output.write(\"# ---> 조회 내역이 없음\\n\")\n",
    "            continue\n",
    "        html_json = pd.read_json(html_output, encoding=\"utf-8\")\n",
    "        html_json = html_json.list.apply(pd.Series)\n",
    "        print(\"# 접수번호, 취득방법 대분류, 취득방법 중분류, 취득방법 소분류, 주식 종류, 기초 수량, 변동 수량 취득, 변동 수량 처분, 변동 수량 소각, 기말 수량, 비고\")\n",
    "        output.write(\"# 접수번호, 취득방법 대분류, 취득방법 중분류, 취득방법 소분류, 주식 종류, 기초 수량, 변동 수량 취득, 변동 수량 처분, 변동 수량 소각, 기말 수량, 비고\\n\")\n",
    "        print(html_json[['rcept_no', 'acqs_mth1', 'acqs_mth2', 'acqs_mth3', 'stock_knd', 'bsis_qy', 'change_qy_acqs', 'change_qy_dsps', 'change_qy_incnr', 'rm']])\n",
    "        print(\"%s \\n\" % html_json[['rcept_no', 'acqs_mth1', 'acqs_mth2', 'acqs_mth3', 'stock_knd', 'bsis_qy', 'change_qy_acqs', 'change_qy_dsps', 'change_qy_incnr', 'rm']])\n",
    "        print(\"\")\n",
    "\n",
    "    output.write(\"\\n\")\n",
    "    output.close()\n",
    "\n",
    "def __Dart_Search_Emp(Dart_Corp_Code, Dart_Exp_Code, File_Name) :\n",
    "\n",
    "    output = open(File_Name, 'a+t')\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    print(\"# 직원 현황\")\n",
    "    output.write(\"# 직원 현황\\n\")\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "\n",
    "    BEGIN_Y_DATE = int(\"2015\")\n",
    "    TODATE_Y_DATE = int(datetime.datetime.today().strftime(\"%Y\"))+1\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                                'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                                'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "                'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "                'Accept-Encoding': 'none', \\\n",
    "                'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "                'Connection': 'keep-alive'}\n",
    "\n",
    "    for x in range(BEGIN_Y_DATE, TODATE_Y_DATE) :\n",
    "        url = \"http://opendart.fss.or.kr/api/empSttus.json?crtfc_key=0fcb8ef56cf8e8b996d47937a8fea5aba8c8d1be&corp_code=\" \\\n",
    "            + Dart_Corp_Code + \"&bsns_year=\" + str(x) + \"&reprt_code=11011\"\n",
    "        print(url)\n",
    "        output.write(\"%s \\n\" % url)\n",
    "        req = Request(url=url, headers=headers)\n",
    "        html = urlopen(req).read()\n",
    "        html_output = html.decode('utf-8')\n",
    "        print(\"# %s년 직원현황\" % x)\n",
    "        output.write(\"# %s년 직원현황\\n\" % x)\n",
    "        if \"013\" in html_output : # {\"status\":\"013\",\"message\":\"조회된 데이타가 없습니다.\"}\n",
    "            print(\"# ---> 조회 내역이 없음\")\n",
    "            output.write(\"# ---> 조회 내역이 없음\\n\")\n",
    "            continue\n",
    "        html_json = pd.read_json(html_output, encoding=\"utf-8\")\n",
    "        html_json = html_json.list.apply(pd.Series)\n",
    "        print(\"# 접수번호, 성별, 사업부문, 정규직 수, 계약직 수, 합계, 평균근속연수, 1인평균 급여, 비고\")\n",
    "        output.write(\"# 접수번호, 성별, 사업부문, 정규직 수, 계약직 수, 합계, 평균근속연수, 1인평균 급여, 비고\\n\")\n",
    "        print(html_json[['rcept_no', 'sexdstn', 'fo_bbm', 'rgllbr_co', 'cnttk_co', 'sm', 'avrg_cnwk_sdytrn', 'jan_salary_am', 'rm']])\n",
    "        output.write(\"%s \\n\" % html_json[['rcept_no', 'sexdstn', 'fo_bbm', 'rgllbr_co', 'cnttk_co', 'sm', 'avrg_cnwk_sdytrn', 'jan_salary_am', 'rm']])\n",
    "        print(\"\")\n",
    "\n",
    "    output.write(\"\\n\")\n",
    "    output.close()\n",
    "\n",
    "def __Dart_Search_Report(Dart_Corp_Code, Dart_Exp_Code, File_Name) :\n",
    "\n",
    "    output = open(File_Name, 'a+t')\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    print(\"# 재무제표 확인 : 단일회사 전체 재무제표 개발가이드\")\n",
    "    output.write(\"# 재무제표 확인 : 단일회사 전체 재무제표 개발가이드\\n\")\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    " \n",
    "    BEGIN_Y_DATE = int(\"2015\")\n",
    "    TODATE_Y_DATE = int(datetime.datetime.today().strftime(\"%Y\"))+1\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                                'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                                'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "                'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "                'Accept-Encoding': 'none', \\\n",
    "                'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "                'Connection': 'keep-alive'}\n",
    "\n",
    "    # 재무정보 가져오기\n",
    "    for x in range(BEGIN_Y_DATE, TODATE_Y_DATE) :\n",
    "        url = \"https://opendart.fss.or.kr/api/fnlttSinglAcnt.json?crtfc_key=0fcb8ef56cf8e8b996d47937a8fea5aba8c8d1be&corp_code=\" \\\n",
    "        + Dart_Corp_Code + \"&bsns_year=\" + str(x) + \"&reprt_code=11011\"\n",
    "        print(url)\n",
    "        output.write(\"%s \\n\" % url)\n",
    "        req = Request(url=url, headers=headers)\n",
    "        html = urlopen(req).read()\n",
    "        html_output = html.decode('utf-8')\n",
    "        print(\"############################################################\")\n",
    "        output.write(\"############################################################\\n\")\n",
    "        print(\"# %s년 재무재표.......\" % x)\n",
    "        output.write(\"# %s년 재무재표.......\\n\" % x)\n",
    "        if \"조회된\" in html_output : # {\"status\":\"013\",\"message\":\"조회된 데이타가 없습니다.\"}\n",
    "            print(\"# ---> 조회 내역이 없음\")\n",
    "            output.write(\"# ---> 조회 내역이 없음\\n\")\n",
    "            continue\n",
    "        print(html_output) # ---> 재무제표 출력\n",
    "\n",
    "        html_json = pd.read_json(html_output, encoding=\"utf-8\")\n",
    "        html_json = html_json.list.apply(pd.Series)\n",
    "        # print(html_json)\n",
    "        # print(html_json[['reprt_code','bsns_year', 'fs_div', 'fs_nm', 'sj_div', 'sj_nm', 'account_nm', 'thstrm_dt', 'thstrm_amount', 'frmtrm_dt', 'frmtrm_amount', 'bfefrmtrm_dt', 'bfefrmtrm_amount', 'ord']])\n",
    "        # print(html_json[['bsns_year', 'fs_nm', 'sj_nm', 'account_nm', 'thstrm_dt', 'thstrm_amount', 'frmtrm_dt', 'frmtrm_amount', 'bfefrmtrm_dt', 'bfefrmtrm_amount', 'ord']])\n",
    "\n",
    "        # print(\"############################################################\")\n",
    "        # print(html_json.columns)\n",
    "        # print(html_json.values)\n",
    "        # print(\"############################################################\")\n",
    "        # print(html_json[html_json['account_nm'].str.match('매출액')])\n",
    "        # print(\"\")\n",
    "        # print(html_json[html_json['account_nm'].str.match('영업이익')])\n",
    "        # print(\"\")\n",
    "        # print(html_json[html_json['account_nm'].str.match('법인세차감전 순이익')])\n",
    "        # print(\"\")\n",
    "        # print(html_json[html_json['account_nm'].str.match('당기순이익')])\n",
    "        # print(\"\")\n",
    "\n",
    "        print(\"############################################################\")\n",
    "        output.write(\"############################################################\\n\")\n",
    "        print(\"# 재무재표 정제해서 출력.......\")\n",
    "        output.write(\"# 재무재표 정제해서 출력.......\\n\")\n",
    "        print(\"############################################################\")\n",
    "        output.write(\"############################################################\\n\")\n",
    "        if 'bfefrmtrm_dt' not in html_json : # bfefrmtrm_dt 가 없는 경우도 있다.\n",
    "            print(\"# 마지막 3기가 없음\")\n",
    "            output.write(\"# 마지막 3기가 없음\\n\")\n",
    "            print(html_json.loc[html_json['account_nm']=='영업이익', ['account_nm', 'thstrm_dt', 'thstrm_amount','frmtrm_dt', 'frmtrm_amount']])\n",
    "            output.write(\"%s\\n\" % html_json.loc[html_json['account_nm']=='영업이익', ['account_nm', 'thstrm_dt', 'thstrm_amount','frmtrm_dt', 'frmtrm_amount']])\n",
    "            print(html_json.loc[html_json['account_nm']=='법인세차감전 순이익', ['account_nm', 'thstrm_dt', 'thstrm_amount','frmtrm_dt', 'frmtrm_amount']])\n",
    "            output.write(\"%s\\n\" % html_json.loc[html_json['account_nm']=='법인세차감전 순이익', ['account_nm', 'thstrm_dt', 'thstrm_amount','frmtrm_dt', 'frmtrm_amount']])\n",
    "            print(html_json.loc[html_json['account_nm']=='당기순이익', ['account_nm', 'thstrm_dt', 'thstrm_amount','frmtrm_dt', 'frmtrm_amount']])\n",
    "            output.write(\"%s\\n\" % html_json.loc[html_json['account_nm']=='당기순이익', ['account_nm', 'thstrm_dt', 'thstrm_amount','frmtrm_dt', 'frmtrm_amount']])\n",
    "        elif 'frmtrm_dt' not in html_json :\n",
    "            print(\"# 마지막 2기가 없음\")\n",
    "            output.write(\"# 마지막 2기가 없음\\n\")\n",
    "            print(html_json.loc[html_json['account_nm']=='영업이익', ['account_nm', 'thstrm_dt', 'thstrm_amount']])\n",
    "            output.write(\"%s\\n\" % html_json.loc[html_json['account_nm']=='영업이익', ['account_nm', 'thstrm_dt', 'thstrm_amount']])\n",
    "            print(html_json.loc[html_json['account_nm']=='법인세차감전 순이익', ['account_nm', 'thstrm_dt', 'thstrm_amount']])\n",
    "            output.write(\"%s\\n\" % html_json.loc[html_json['account_nm']=='법인세차감전 순이익', ['account_nm', 'thstrm_dt', 'thstrm_amount']])\n",
    "            print(html_json.loc[html_json['account_nm']=='당기순이익', ['account_nm', 'thstrm_dt', 'thstrm_amount']])\n",
    "            output.write(\"%s\\n\" % html_json.loc[html_json['account_nm']=='당기순이익', ['account_nm', 'thstrm_dt', 'thstrm_amount']])\n",
    "        else :\n",
    "            print(html_json.loc[html_json['account_nm']=='영업이익', ['account_nm', 'thstrm_dt', 'thstrm_amount','frmtrm_dt', 'frmtrm_amount', 'bfefrmtrm_dt', 'bfefrmtrm_amount']])\n",
    "            output.write(\"%s\\n\" % html_json.loc[html_json['account_nm']=='영업이익', ['account_nm', 'thstrm_dt', 'thstrm_amount','frmtrm_dt', 'frmtrm_amount', 'bfefrmtrm_dt', 'bfefrmtrm_amount']])\n",
    "            print(html_json.loc[html_json['account_nm']=='법인세차감전 순이익', ['account_nm', 'thstrm_dt', 'thstrm_amount','frmtrm_dt', 'frmtrm_amount', 'bfefrmtrm_dt', 'bfefrmtrm_amount']])\n",
    "            output.write(\"%s\\n\" % html_json.loc[html_json['account_nm']=='법인세차감전 순이익', ['account_nm', 'thstrm_dt', 'thstrm_amount','frmtrm_dt', 'frmtrm_amount', 'bfefrmtrm_dt', 'bfefrmtrm_amount']])\n",
    "            print(html_json.loc[html_json['account_nm']=='당기순이익', ['account_nm', 'thstrm_dt', 'thstrm_amount','frmtrm_dt', 'frmtrm_amount', 'bfefrmtrm_dt', 'bfefrmtrm_amount']])\n",
    "            output.write(\"%s\\n\" % html_json.loc[html_json['account_nm']=='당기순이익', ['account_nm', 'thstrm_dt', 'thstrm_amount','frmtrm_dt', 'frmtrm_amount', 'bfefrmtrm_dt', 'bfefrmtrm_amount']])\n",
    "\n",
    "    TODATE_Y_DATE = int(datetime.datetime.today().strftime(\"%Y\"))\n",
    "    TODATE_Y_DATE = int(datetime.datetime.today().strftime(\"%Y\"))-1\n",
    "    print(int(datetime.datetime.today().strftime(\"%Y\")))\n",
    "    print(int(datetime.datetime.today().strftime(\"%Y\"))-1)\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    print(\"# 마지막만 정제 ---> %s .......1\" % TODATE_Y_DATE)\n",
    "    output.write(\"# 마지막만 정제 ---> %s .......1\\n\" % TODATE_Y_DATE)\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    url = \"https://opendart.fss.or.kr/api/fnlttSinglAcnt.json?crtfc_key=0fcb8ef56cf8e8b996d47937a8fea5aba8c8d1be&corp_code=\" \\\n",
    "        + Dart_Corp_Code + \"&bsns_year=\" + str(TODATE_Y_DATE) + \"&reprt_code=11011\"\n",
    "    print(url)\n",
    "    output.write(\"%s \\n\" % url)\n",
    "    req = Request(url=url, headers=headers)\n",
    "    html = urlopen(req).read()\n",
    "    html_output = html.decode('utf-8')\n",
    "    if \"조회된\" in html_output : # {\"status\":\"013\",\"message\":\"조회된 데이타가 없습니다.\"}\n",
    "        TODATE_Y_DATE = int(datetime.datetime.today().strftime(\"%Y\"))-2\n",
    "        print(\"# ---> 조회 내역이 없음 ---> 그 이전 년도 조회 : %s\" % TODATE_Y_DATE)\n",
    "        output.write(\"# ---> 조회 내역이 없음 ---> 그 이전 년도 조회 : %s\\n\" % TODATE_Y_DATE)\n",
    "        url = \"https://opendart.fss.or.kr/api/fnlttSinglAcnt.json?crtfc_key=0fcb8ef56cf8e8b996d47937a8fea5aba8c8d1be&corp_code=\" \\\n",
    "            + Dart_Corp_Code + \"&bsns_year=\" + str(TODATE_Y_DATE) + \"&reprt_code=11011\"\n",
    "        print(url)\n",
    "        output.write(\"%s \\n\" % url)\n",
    "        req = Request(url=url, headers=headers)\n",
    "        html = urlopen(req).read()\n",
    "        html_output = html.decode('utf-8')\n",
    "\n",
    "    html_json = pd.read_json(html_output, encoding=\"utf-8\")\n",
    "    html_json = html_json.list.apply(pd.Series)\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    print(\"# 마지막만 정제.......2\")\n",
    "    output.write(\"# 마지막만 정제.......2\\n\")\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "\n",
    "    print(\"# 매출액\")\n",
    "    output.write(\"# 매출액\\n\")\n",
    "    print(\"############################################################\\n\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    sales_1_name = html_json.loc[html_json['account_nm']=='매출액', ['thstrm_nm']].values[0]\n",
    "    sales_1_value = html_json.loc[html_json['account_nm']=='매출액', ['thstrm_amount']].values[0]\n",
    "    sales_2_name = html_json.loc[html_json['account_nm']=='매출액', ['frmtrm_nm']].values[0]\n",
    "    sales_2_value = html_json.loc[html_json['account_nm']=='매출액', ['frmtrm_amount']].values[0]\n",
    "    sales_3_name = html_json.loc[html_json['account_nm']=='매출액', ['bfefrmtrm_nm']].values[0]\n",
    "    sales_3_value = html_json.loc[html_json['account_nm']=='매출액', ['bfefrmtrm_amount']].values[0]\n",
    "\n",
    "    # print(type(sales_1_name)) # ---> <class 'numpy.ndarray'>\n",
    "    # print(type(sales_1_name.tostring())) # ---> <class 'bytes'>\n",
    "    # print(type(int.from_bytes(sales_1_name.tostring(), byteorder='big'))) # ---> <class 'bytes'>\n",
    "    # print(type(int.from_bytes(sales_1_name.tostring(), byteorder='little'))) # ---> <class 'bytes'>\n",
    "    # test_value1 = int.from_bytes(sales_1_name.tostring(), byteorder='big')\n",
    "    # test_value2 = int.from_bytes(sales_1_name.tostring(), byteorder='little')\n",
    "    # print(test_value1/8192)\n",
    "    # print(test_value2)\n",
    "\n",
    "    # print(type(sales_1_value))\n",
    "    # print(\"############################################################\")\n",
    "\n",
    "    print(\"%s : %s \" % (sales_1_name, sales_1_value))\n",
    "    output.write(\"%s : %s \\n\" % (sales_1_name, sales_1_value))\n",
    "    print(\"%s : %s \" % (sales_2_name, sales_2_value))\n",
    "    output.write(\"%s : %s \\n\" % (sales_2_name, sales_2_value))\n",
    "    print(\"%s : %s \" % (sales_3_name, sales_3_value))\n",
    "    output.write(\"%s : %s \\n\" % (sales_3_name, sales_3_value))\n",
    "    print(\"\")\n",
    "    output.write(\"\\n\")\n",
    "    sales_name_list = list(sales_1_name)\n",
    "    sales_name_list.append(sales_2_name)\n",
    "    sales_name_list.append(sales_3_name)\n",
    "    sales_value_list = list(sales_1_value)\n",
    "    sales_value_list.append(sales_2_value)\n",
    "    sales_value_list.append(sales_3_value)\n",
    "    # print(\"############################################################\")\n",
    "    # print(sales_name_list)\n",
    "    # print(sales_value_list)\n",
    "    # print(\"############################################################\")\n",
    "    # plt.plot(sales_name_list, sales_value_list)\t# line 그래프를 그립니다\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    # plt.show()\t# 그래프를 화면에 보여줍니다\n",
    " \n",
    "    print(\"# 영업이익\")\n",
    "    output.write(\"# 영업이익\\n\")\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    profit_1_name = html_json.loc[html_json['account_nm']=='영업이익', ['thstrm_nm']].values[0]\n",
    "    profit_1_value = html_json.loc[html_json['account_nm']=='영업이익', ['thstrm_amount']].values[0]\n",
    "    profit_2_name = html_json.loc[html_json['account_nm']=='영업이익', ['frmtrm_nm']].values[0]\n",
    "    profit_2_value = html_json.loc[html_json['account_nm']=='영업이익', ['frmtrm_amount']].values[0]\n",
    "    profit_3_name = html_json.loc[html_json['account_nm']=='영업이익', ['bfefrmtrm_nm']].values[0]\n",
    "    profit_3_value = html_json.loc[html_json['account_nm']=='영업이익', ['bfefrmtrm_amount']].values[0]\n",
    "\n",
    "    print(\"%s : %s\" % (profit_1_name, profit_1_value))\n",
    "    output.write(\"%s : %s\\n\" % (profit_1_name, profit_1_value))\n",
    "    print(\"%s : %s\" % (profit_2_name, profit_2_value))\n",
    "    output.write(\"%s : %s\\n\" % (profit_2_name, profit_2_value))\n",
    "    print(\"%s : %s\" % (profit_3_name, profit_3_value))\n",
    "    output.write(\"%s : %s\\n\" % (profit_3_name, profit_3_value))\n",
    "    print(\"\")\n",
    "    output.write(\"\\n\")\n",
    "\n",
    "    CorporateTax_1_name = html_json.loc[html_json['account_nm']=='법인세차감전 순이익', ['thstrm_nm']].values[0]\n",
    "    CorporateTax_1_value = html_json.loc[html_json['account_nm']=='법인세차감전 순이익', ['thstrm_amount']].values[0]\n",
    "    CorporateTax_2_name = html_json.loc[html_json['account_nm']=='법인세차감전 순이익', ['frmtrm_nm']].values[0]\n",
    "    CorporateTax_2_value = html_json.loc[html_json['account_nm']=='법인세차감전 순이익', ['frmtrm_amount']].values[0]\n",
    "    CorporateTax_3_name = html_json.loc[html_json['account_nm']=='법인세차감전 순이익', ['bfefrmtrm_nm']].values[0]\n",
    "    CorporateTax_3_value = html_json.loc[html_json['account_nm']=='법인세차감전 순이익', ['bfefrmtrm_amount']].values[0]\n",
    "\n",
    "    print(\"# 법인세차감전 순이익\")\n",
    "    output.write(\"# 법인세차감전 순이익\\n\")\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    print(\"%s : %s \" % (CorporateTax_1_name, CorporateTax_1_value))\n",
    "    output.write(\"%s : %s\\n\" % (CorporateTax_1_name, CorporateTax_1_value))\n",
    "    print(\"%s : %s \" % (CorporateTax_2_name, CorporateTax_2_value))\n",
    "    output.write(\"%s : %s\\n\" % (CorporateTax_2_name, CorporateTax_2_value))\n",
    "    print(\"%s : %s \" % (CorporateTax_3_name, CorporateTax_3_value))\n",
    "    output.write(\"%s : %s\\n\" % (CorporateTax_3_name, CorporateTax_3_value))\n",
    "    print(\"\")\n",
    "    output.write(\"\\n\")\n",
    "\n",
    "    NetIncome_tax_1_name = html_json.loc[html_json['account_nm']=='당기순이익', ['thstrm_nm']].values[0]\n",
    "    NetIncome_tax_1_value = html_json.loc[html_json['account_nm']=='당기순이익', ['thstrm_amount']].values[0]\n",
    "    NetIncome_tax_2_name = html_json.loc[html_json['account_nm']=='당기순이익', ['frmtrm_nm']].values[0]\n",
    "    NetIncome_tax_2_value = html_json.loc[html_json['account_nm']=='당기순이익', ['frmtrm_amount']].values[0]\n",
    "    NetIncome_tax_3_name = html_json.loc[html_json['account_nm']=='당기순이익', ['bfefrmtrm_nm']].values[0]\n",
    "    NetIncome_tax_3_value = html_json.loc[html_json['account_nm']=='당기순이익', ['bfefrmtrm_amount']].values[0]\n",
    "\n",
    "    print(\"# 당기 순이익\")\n",
    "    output.write(\"# 당기 순이익\\n\")\n",
    "    print(\"############################################################\")\n",
    "    output.write(\"############################################################\\n\")\n",
    "    print(\"%s : %s \" % (NetIncome_tax_1_name, NetIncome_tax_1_value))\n",
    "    output.write(\"%s : %s\\n\" % (NetIncome_tax_1_name, NetIncome_tax_1_value))\n",
    "    print(\"%s : %s \" % (NetIncome_tax_2_name, NetIncome_tax_2_value))\n",
    "    output.write(\"%s : %s\\n\" % (NetIncome_tax_2_name, NetIncome_tax_2_value))\n",
    "    print(\"%s : %s \" % (NetIncome_tax_3_name, NetIncome_tax_3_value))\n",
    "    output.write(\"%s : %s\\n\" % (NetIncome_tax_3_name, NetIncome_tax_3_value))\n",
    "    print(\"\")\n",
    "    output.write(\"\\n\")\n",
    "\n",
    "    output.write(\"\\n\")\n",
    "    output.close()\n",
    "\n",
    "def __Dart_Search_Report_Detail(Dart_Corp_Code, Dart_Exp_Code, File_Name) :\n",
    "\n",
    "    BEGIN_Y_DATE = int(\"2015\")\n",
    "    TODATE_Y_DATE = int(datetime.datetime.today().strftime(\"%Y\"))+1\n",
    "\n",
    "    output = open(File_Name, 'a+t')\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                                'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                                'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "                'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "                'Accept-Encoding': 'none', \\\n",
    "                'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "                'Connection': 'keep-alive'}\n",
    "\n",
    "    url = \"https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json?crtfc_key=0fcb8ef56cf8e8b996d47937a8fea5aba8c8d1be&corp_code=\" \\\n",
    "        + Dart_Corp_Code + \"&bsns_year=\" + str(TODATE_Y_DATE) + \"&reprt_code=11011&fs_div=OFS\"\n",
    "    print(url)\n",
    "    output.write(\"%s \\n\" % url)\n",
    "    req = Request(url=url, headers=headers)\n",
    "    html = urlopen(req).read()\n",
    "    html_output = html.decode('utf-8')\n",
    "\n",
    "    # print(\"# html_output 1\")\n",
    "    # print(html_output)\n",
    "\n",
    "    if \"조회된\" in html_output : # {\"status\":\"013\",\"message\":\"조회된 데이타가 없습니다.\"}\n",
    "        TODATE_Y_DATE = int(datetime.datetime.today().strftime(\"%Y\"))-2\n",
    "        print(\"# ---> 조회 내역이 없음 ---> 그 이전 년도 조회 : %s\" % TODATE_Y_DATE)\n",
    "        output.write(\"# ---> 조회 내역이 없음 ---> 그 이전 년도 조회 : %s\\n\" % TODATE_Y_DATE)\n",
    "        url = \"https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json?crtfc_key=0fcb8ef56cf8e8b996d47937a8fea5aba8c8d1be&corp_code=\" \\\n",
    "            + Dart_Corp_Code + \"&bsns_year=\" + str(TODATE_Y_DATE) + \"&reprt_code=11011&fs_div=OFS\"\n",
    "        print(url)\n",
    "        output.write(\"%s \\n\" % url)\n",
    "        req = Request(url=url, headers=headers)\n",
    "        html = urlopen(req).read()\n",
    "        html_output = html.decode('utf-8')\n",
    "        # ---> 아래 또 없다면 종료\n",
    "        if \"조회된\" in html_output : # {\"status\":\"013\",\"message\":\"조회된 데이타가 없습니다.\"}\n",
    "            TODATE_Y_DATE = int(datetime.datetime.today().strftime(\"%Y\"))-2\n",
    "            print(\"# ---> 또 조회 내역이 없음 ---> 종료\\n\")\n",
    "            output.write(\"# ---> 또 조회 내역이 없음 ---> 종료\\n\")\n",
    "            return None\n",
    "\n",
    "        # print(\"# html_output 2\")\n",
    "        # print(html_output)\n",
    "\n",
    "    html_json = pd.read_json(html_output, encoding=\"utf-8\")\n",
    "    html_json = html_json.list.apply(pd.Series)\n",
    "\n",
    "    print(\"########## html_json extract\")\n",
    "    # print(html_json.loc[html_json['sj_div']=='CF'])\n",
    "    Extract_Data = html_json.loc[html_json['sj_div']=='CF']\n",
    "    if 'frmtrm_nm' in Extract_Data.columns :\n",
    "        print(Extract_Data[['account_nm', 'account_detail', 'thstrm_nm', 'thstrm_amount']])\n",
    "    elif 'bfefrmtrm_nm' in Extract_Data.columns :\n",
    "        print(Extract_Data[['account_nm', 'account_detail', 'thstrm_nm', 'thstrm_amount', 'frmtrm_nm', 'frmtrm_amount']])\n",
    "    else :\n",
    "        print(Extract_Data[['account_nm', 'account_detail', 'thstrm_nm', 'thstrm_amount', 'frmtrm_nm', 'frmtrm_amount', 'bfefrmtrm_nm', 'bfefrmtrm_amount']])\n",
    "\n",
    "    # CashFlow_1_name = html_json.loc[html_json['account_nm']=='영업활동현금흐름', ['thstrm_nm']].values[0]\n",
    "    # IndexError: index 0 is out of bounds for axis 0 with size 0\n",
    "    if 'frmtrm_nm' in Extract_Data.columns and 'bfefrmtrm_nm' in Extract_Data.columns :\n",
    "        CashFlow_1_name = html_json.loc[html_json['account_nm']=='영업활동현금흐름', ['thstrm_nm']].values[0]\n",
    "        CashFlow_1_value = html_json.loc[html_json['account_nm']=='영업활동현금흐름', ['thstrm_amount']].values[0]\n",
    "        CashFlow_2_name = html_json.loc[html_json['account_nm']=='영업활동현금흐름', ['frmtrm_nm']].values[0]\n",
    "        CashFlow_2_value = html_json.loc[html_json['account_nm']=='영업활동현금흐름', ['frmtrm_amount']].values[0]\n",
    "        CashFlow_3_name = html_json.loc[html_json['account_nm']=='영업활동현금흐름', ['bfefrmtrm_nm']].values[0]\n",
    "        CashFlow_3_value = html_json.loc[html_json['account_nm']=='영업활동현금흐름', ['bfefrmtrm_amount']].values[0]\n",
    "\n",
    "        print(\"############################################################\")\n",
    "        output.write(\"############################################################\\n\")\n",
    "        print(\"# 영업활동현금흐름\")\n",
    "        output.write(\"# 영업활동현금흐름\\n\")\n",
    "        print(\"############################################################\")\n",
    "        output.write(\"############################################################\\n\")\n",
    "        print(\"%s : %s \" % (CashFlow_1_name, CashFlow_1_value))\n",
    "        output.write(\"%s : %s\\n\" % (CashFlow_1_name, CashFlow_1_value))\n",
    "        print(\"%s : %s \" % (CashFlow_2_name, CashFlow_2_value))\n",
    "        output.write(\"%s : %s\\n\" % (CashFlow_2_name, CashFlow_2_value))\n",
    "        print(\"%s : %s \" % (CashFlow_3_name, CashFlow_3_value))\n",
    "        output.write(\"%s : %s\\n\" % (CashFlow_3_name, CashFlow_3_value))\n",
    "        print(\"\")\n",
    "        output.write(\"\\n\")\n",
    "\n",
    "        # QuarterProfit_1_name = html_json.loc[html_json['account_nm']=='당기순이익(손실)', ['thstrm_nm']].values[0]\n",
    "        # IndexError: index 0 is out of bounds for axis 0 with size 0\n",
    "        # ---> (손실) 이 없을 경우도 있다.\n",
    "        QuarterProfit_1_name = html_json.loc[html_json['account_nm']=='당기순이익(손실)', ['thstrm_nm']].values[0]\n",
    "        QuarterProfit_1_value = html_json.loc[html_json['account_nm']=='당기순이익(손실)', ['thstrm_amount']].values[0]\n",
    "        QuarterProfit_2_name = html_json.loc[html_json['account_nm']=='당기순이익(손실)', ['frmtrm_nm']].values[0]\n",
    "        QuarterProfit_2_value = html_json.loc[html_json['account_nm']=='당기순이익(손실)', ['frmtrm_amount']].values[0]\n",
    "        QuarterProfit_3_name = html_json.loc[html_json['account_nm']=='당기순이익(손실)', ['bfefrmtrm_nm']].values[0]\n",
    "        QuarterProfit_3_value = html_json.loc[html_json['account_nm']=='당기순이익(손실)', ['bfefrmtrm_amount']].values[0]\n",
    "\n",
    "        print(\"############################################################\")\n",
    "        output.write(\"############################################################\\n\")\n",
    "        print(\"# 당기순이익(손실)\")\n",
    "        output.write(\"# 당기순이익(손실)\\n\")\n",
    "        print(\"############################################################\")\n",
    "        output.write(\"############################################################\\n\")\n",
    "        print(\"%s : %s \" % (QuarterProfit_1_name, QuarterProfit_1_value))\n",
    "        output.write(\"%s : %s\\n\" % (QuarterProfit_1_name, QuarterProfit_1_value))\n",
    "        print(\"%s : %s \" % (QuarterProfit_2_name, QuarterProfit_2_value))\n",
    "        output.write(\"%s : %s\\n\" % (QuarterProfit_2_name, QuarterProfit_2_value))\n",
    "        print(\"%s : %s \" % (QuarterProfit_3_name, QuarterProfit_3_value))\n",
    "        output.write(\"%s : %s\\n\" % (QuarterProfit_3_name, QuarterProfit_3_value))\n",
    "        print(\"\")\n",
    "        output.write(\"\\n\")\n",
    "    else :\n",
    "        print(\"############################################################\")\n",
    "        output.write(\"############################################################\\n\")\n",
    "        print(\"# 전기, 전전기 없음\")\n",
    "        output.write(\"# 전기, 전전기 없음\\n\")\n",
    "        print(\"############################################################\")\n",
    "        output.write(\"############################################################\\n\")\n",
    "        print(\"\")\n",
    "        output.write(\"\\n\")\n",
    "\n",
    "def __Dart_Search_Attention(Dart_Corp_Code, Dart_Exp_Code, File_Name, rcpno) :\n",
    "\n",
    "    output = open(File_Name, 'a+t')\n",
    "\n",
    "    BEGIN_Y_DATE = int(\"2015\")\n",
    "    TODATE_Y_DATE = int(datetime.datetime.today().strftime(\"%Y\"))+1\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                                'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                                'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "                'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "                'Accept-Encoding': 'none', \\\n",
    "                'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "                'Connection': 'keep-alive'}\n",
    "\n",
    "    url = \"https://dart.fss.or.kr/dsaf001/main.do?rcpNo=\" + rcpno\n",
    "    print(\"###############################################1\")\n",
    "    print(url)\n",
    "\n",
    "    # https://github.com/guineapi9/guineapig/blob/master/재무제표%20크롤링\n",
    "    req2=requests.get(url)\n",
    "    html2=req2.text\n",
    "    soup2=BeautifulSoup(html2, 'html.parser')\n",
    "    # 재무제표 페이지 찾기\n",
    "    body=str(soup2.find('head'))\n",
    "    a=re.search(' 재무제표', body).span()\n",
    "    print(a)\n",
    "    # 요약재무정보 근처에서 숫자 정보 찾기(자바스크립트로 되어있지만 정규표현식으로 검색)\n",
    "    b=re.search(r'viewDoc(.*);',body[a[0]:a[1]+1000]).group()\n",
    "    print(\"######## 04\")\n",
    "    # 30번 : XI. 그 밖에 투자자 보호를 위하여 필요한 사항\n",
    "    print(b)\n",
    "    # 필요없는 부분 제거\n",
    "    list=b[8:-2].split(', ')\n",
    "    list=[i[1:-1] for i in list]\n",
    "    url_final_1='http://dart.fss.or.kr/report/viewer.do?rcpNo='+list[0]+'&dcmNo='+list[1]+'&eleId='+list[2]+'&offset='+list[3]+'&length='+list[4]+'&dtd=dart3.xsd'\n",
    "    url_final_2='http://dart.fss.or.kr/report/viewer.do?rcpNo='+list[0]+'&dcmNo='+list[1]+'&eleId='+\"30\"+'&offset='+list[3]+'&length='+list[4]+'&dtd=dart3.xsd'\n",
    "    # url = \"https://dart.fss.or.kr/report/viewer.do?rcpNo=20200814000814&dcmNo=7442872&eleId=30&offset=678&length=4626&dtd=dart3.xsd\"\n",
    "    # url = \"https://dart.fss.or.kr/report/viewer.do?rcpNo=20201116000449&dcmNo=7442872&eleId=30&offset=678&length=4626&dtd=dart3.xsd\"\n",
    "    # url = \"https://dart.fss.or.kr/report/viewer.do?rcpNo=20200814000814&dcmNo=7442872&eleId=30&offset=678&length=4626&dtd=dart3.xsd\"\n",
    "    print('재무제표 상태표 url = '+url_final_1)\n",
    "    print('재무제표 투자자 보호 url = '+url_final_2)\n",
    "    # for x in list :\n",
    "    #     print(\"########\")\n",
    "    #     print(x)\n",
    "\n",
    "    output.write(\"\\n\")\n",
    "    output.close()\n",
    "\n",
    "def __Last_Page_Numb(company_code) :\n",
    "\n",
    "    url = \"https://finance.naver.com/item/sise_day.nhn?code=\" + company_code\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "        'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "        'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "        'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "        'Accept-Encoding': 'none', \\\n",
    "        'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "        'Connection': 'keep-alive'}\n",
    "\n",
    "    req = Request(url=url, headers=headers)\n",
    "    html = urlopen(req).read()\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    table = bs_object.find('td', attrs={'class':'pgRR'})\n",
    "\n",
    "    for x in table.find_all('a') :\n",
    "        test = x['href']\n",
    "        active = test.split(\"=\")\n",
    "        page_num = active[2]\n",
    "\n",
    "    print(\"# Company Page_Number : \", page_num)\n",
    "    return page_num\n",
    "\n",
    "def __Last_Page_Numb_Market(Market) :\n",
    "    if Market == \"KOSPI\" :\n",
    "        url = \"https://finance.naver.com/sise/sise_index_day.nhn?code=KOSPI&page=1\"\n",
    "        # print(url)\n",
    "    elif Market == \"KOSDAQ\" :\n",
    "        url = \"https://finance.naver.com/sise/sise_index_day.nhn?code=KOSDAQ&page=1\"\n",
    "        # print(url)\n",
    "\n",
    "    html = urlopen(url, context=context)\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    main1_pages = bs_object.find_all(\"a\")\n",
    "    for a_list in main1_pages:\n",
    "        if a_list is main1_pages[-1] :\n",
    "            last_page=a_list.attrs['href']\n",
    "        else :\n",
    "            continue\n",
    "        page_num: object=last_page.split('=')\n",
    "        print(\"# Market Page_Number : \", page_num[2])\n",
    "        return page_num[2]\n",
    "\n",
    "def __Price_Find(company_code, page):\n",
    "    page = int(page)\n",
    "    df_list, date_list, closing_list, gap_list, gap_perf  = [], [], [], [], []\n",
    "\n",
    "    date_list, closing_list = [], []\n",
    "    # for page_num in range(1, page) :\n",
    "    for page_num in range(1, 125) : # ---> 1페이지 당 10일, 250일이 년중 평일이라 하면 25페이지가 1년, 125페이지가 5년.\n",
    "        url= \"https://finance.naver.com/item/sise_day.nhn?code=\" + company_code + \"&page=\" + str(page_num)\n",
    "        print(url)\n",
    "\n",
    "        req = Request(url=url, headers=headers)\n",
    "\n",
    "        try :\n",
    "            html = urlopen(req).read()\n",
    "            # html = urlopen(url, context=context)\n",
    "        except HTTPError as err:\n",
    "            if err.code == 404 :\n",
    "                print(\"# Error HTTP : 404\")\n",
    "                return\n",
    "            elif err.code == 403 :\n",
    "                print(\"# Error HTTP : 403\")\n",
    "                return\n",
    "            elif err.code == 500 :\n",
    "                print(\"# Error HTTP : 500\")\n",
    "                return\n",
    "            elif err.code == 505:\n",
    "                print(\"# Error HTTP : 505\")\n",
    "                return\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "        table = bs_object.find('table', attrs={'class':'type2'})\n",
    "        table_body = table.find_all('td', attrs={'class':'num'})\n",
    "        date_body = table.find_all('span', attrs={'class':'tah p10 gray03'})\n",
    "\n",
    "        for x in date_body :\n",
    "            # print(\"x.contents type : %s\" % type(x.contents)) # ---> x.contents type : <class 'list'>\n",
    "            date_list.append(x.contents[0])\n",
    "\n",
    "        testlist = []\n",
    "        for tr in table_body :\n",
    "            td = tr.find_all('span', attrs={'class':'tah p11'})\n",
    "            # print(\"for tr type : %s\" % type(td))\n",
    "            for x in td :\n",
    "                # print(\"for x in td : %s\" % type(x)) # ---> for tr type : <class 'bs4.element.ResultSet'>\n",
    "                # print(\"for x.contents in td : %s, %s\" % (type(x.contents), x.contents)) # ---> for x.contents in td : <class 'list'>\n",
    "                # print(\"for x.contents in td : %s, %s\" % (type(x.contents[0]), x.contents[0])) # ---> for x.contents in td : <class 'list'>\n",
    "                # time.sleep(3)\n",
    "                # ----> 테이블 중간에 전일비 값이 0이면 table이 엉망이 됨\n",
    "                # ----> 전일비가 안들어오다가 들어간o\n",
    "                # print(\"X Contennts : %s, %s\" % (x.contents[0], type(x.contents[0])))\n",
    "                # print(\"X Contennts : %s, %s\" % (x.contents[0], type(str(x.contents[0]))))\n",
    "                if str(x.contents[0]) == \"0\" :\n",
    "                    continue\n",
    "                else :\n",
    "                    testlist.append(x.contents[0])\n",
    "            \n",
    "        # print(\"# TEST LIST\")\n",
    "        # print(testlist)\n",
    "\n",
    "        for x in range(0, len(testlist)) :\n",
    "            # print(x, testlist[x])\n",
    "            if x == 0 :\n",
    "                closing_list.append(testlist[x])\n",
    "            else :\n",
    "                result = x % 5\n",
    "                if result == 0 :\n",
    "                    closing_list.append(testlist[x])\n",
    "\n",
    "    # print(\"############## date_list ##################\")\n",
    "    # print(date_list)\n",
    "    # print(\"############## closing_list ##################\")\n",
    "    # print(closing_list)\n",
    "\n",
    "    return date_list, closing_list\n",
    "\n",
    "def __Market_Price(company_code, page):\n",
    "    df_list, date_list, closing_list = [], [], []\n",
    "    # print(\"# Market : %s\" % company_code)\n",
    "\n",
    "    page = int(page)\n",
    "    for page_num in range(1, page) :\n",
    "        url_main = \"https://finance.naver.com/sise/sise_index_day.nhn?code=\" + company_code + \"&page=\" + str(page_num)\n",
    "        # print(\"# url : %s\" % url_main)\n",
    "        code_data = pd.read_html(url_main, header=0, skiprows=(6,7,8)) # ---> code data로 출력을 생성하면 NaN이 1개라인이 남음, Type은 <class 'list'>\n",
    "        df_list.append(pd.read_html(url_main)[0]) # ---> List 로 append, 본문[0]과 페이지 출력[1] 부분 중 본문을 출력\n",
    "\n",
    "    df=pd.concat(df_list)\n",
    "    df.dropna(subset=[\"날짜\"], inplace=True) # ---> Naver에서 출력되는 가운데 날짜 컬럼 NaN 라인들 삭제처리\n",
    "    df.rename(columns={'날짜': 'date'}, inplace = True)\n",
    "    df.rename(columns={'체결가': 'closing'}, inplace = True)\n",
    "    df.rename(columns={'전일비': 'diff'}, inplace = True)\n",
    "    df['new_date'] = pd.to_datetime(df['date']) # ---> dateime 형식으로 new_date 추가\n",
    "    date_list=df.date.values.tolist()\n",
    "    closing_list=df.closing.values.tolist()\n",
    "    for x in range(0, len(closing_list)-1):\n",
    "        closing_list[x] = int(closing_list[x]) # ---> float 에서 int로 변경\n",
    "    date_list.reverse()\n",
    "    closing_list.reverse()\n",
    "\n",
    "    return date_list, closing_list\n",
    "\n",
    "# def __Make_Chart(date_list, KOSPI_List, KOSDAQ_List, Dart_Exp_Code, Comp_Date_List, Comp_Closing_List, Dart_Comp_Name) :\n",
    "def __Make_Chart(Dart_Exp_Code, Dart_Comp_Name, Dart_Market_Name) :\n",
    "\n",
    "    DateTime = datetime.datetime.today().strftime(\"%Y%m%d_%H%M\")\n",
    "    File_Name = \"/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/Ananlyst_\"+Dart_Exp_Name+\"_\"+DateTime+\".html\"\n",
    "    \n",
    "    Comp_Date_List, Comp_Closing_List, KOSPI_DATE_List, KOSPI_List, KOSDAQ_DATE_List, KOSDAQ_List = [], [], [], [], [], []\n",
    "    page = __Last_Page_Numb(Dart_Exp_Code)\n",
    "    KOSPI_Page = __Last_Page_Numb_Market(\"KOSPI\")\n",
    "    KOSDAQ_Page = __Last_Page_Numb_Market(\"KOSDAQ\")\n",
    "\n",
    "    Comp_Date_List, Comp_Closing_List = __Price_Find(Dart_Exp_Code, page)\n",
    "    print(Comp_Date_List)\n",
    "    print(Comp_Closing_List)\n",
    "    KOSPI_Date, KOSPI_List = __Market_Price(\"KOSPI\", KOSPI_Page)\n",
    "    KOSDAQ_Date, KOSDAQ_List = __Market_Price(\"KOSDAQ\", KOSDAQ_Page)\n",
    "\n",
    "    print(\"# KOSPI_DATE : %s, length : %s\" % (KOSPI_Date[0], len(KOSPI_Date)))\n",
    "    print(\"# KOSPI_List : %s, length : %s\" % (KOSPI_List[0], len(KOSPI_List)))\n",
    "    print(\"# KOSDAQ_DATE : %s, length : %s\" % (KOSDAQ_Date[0], len(KOSDAQ_Date)))\n",
    "    print(\"# KOSDAQ_List : %s, length : %s\" % (KOSDAQ_List[0], len(KOSDAQ_List)))\n",
    "    print(\"# Comp DATE : %s, length : %s\" % (Comp_Date_List[0], len(Comp_Date_List)))\n",
    "    print(\"# Comp Closing : %s, length : %s\" % (Comp_Closing_List[0], len(Comp_Date_List)))\n",
    "    print(\"\")\n",
    "\n",
    "    if Dart_Market_Name == '코스피' :\n",
    "        date_list = KOSPI_Date\n",
    "        if len(Comp_Date_List) < len(date_list) : # ---> 코스피 기간이 더 길어서 코스피 삭제\n",
    "            Date_Index = date_list.index(Comp_Date_List[0])\n",
    "            print(Date_Index)\n",
    "            del date_list[0:Date_Index]\n",
    "            del KOSPI_List[0:Date_Index]\n",
    "        else : # ---> 종목 기간이 더 길어서 종목 기간 삭제 ---> 시장보다 길다???\n",
    "            Date_Index = KOSPI_List.index(date_list[0])\n",
    "            print(Date_Index)\n",
    "            del Comp_Date_List[0:Date_Index]\n",
    "            del Comp_Closing_List[0:Date_Index]\n",
    "    elif Dart_Market_Name == '코스닥' :\n",
    "        date_list = KOSDAQ_Date\n",
    "        if len(Comp_Date_List) < len(date_list) : # ---> 코스닥 기간이 더 길어서 코스피 삭제\n",
    "            Date_Index = date_list.index(Comp_Date_List[0])\n",
    "            print(Date_Index)\n",
    "            del date_list[0:Date_Index]\n",
    "            del KOSDAQ_List[0:Date_Index]\n",
    "        else : # ---> 종목 기간이 더 길어서 종목 기간 삭제 ---> 시장보다 길다???\n",
    "            Date_Index = KOSDAQ_List.index(date_list[0])\n",
    "            print(Date_Index)\n",
    "            del Comp_Date_List[0:Date_Index]\n",
    "            del Comp_Closing_List[0:Date_Index]\n",
    "    else :\n",
    "        date_list = KOSPI_Date\n",
    "\n",
    "    print(\"# KOSPI_DATE : %s, length ; %s\" % (KOSPI_Date[0], len(KOSPI_Date)))\n",
    "    print(\"# KOSPI_List : %s, length ; %s\" % (KOSPI_List[0], len(KOSPI_List)))\n",
    "    print(\"# KOSDAQ_DATE : %s, length ; %s\" % (KOSDAQ_Date[0], len(KOSDAQ_Date)))\n",
    "    print(\"# KOSDAQ_List : %s, length ; %s\" % (KOSDAQ_List[0], len(KOSDAQ_List)))\n",
    "    print(\"# Comp DATE : %s, length ; %s\" % (Comp_Date_List[0], len(Comp_Date_List)))\n",
    "    print(\"# Comp Closing : %s, length ; %s\" % (Comp_Closing_List[0], len(Comp_Date_List)))\n",
    "    print(\"\")\n",
    "\n",
    "# KOSPI_DATE : 1990.01.06\n",
    "# KOSPI_List : 912.86\n",
    "# KOSDAQ_DATE : 1996.07.08\n",
    "# KOSDAQ_List : 1048.2\n",
    "# Comp DATE : 2010.01.08\n",
    "\n",
    "    print(\"# date list : %s\" % date_list[0])\n",
    "\n",
    "    input_1 = open('Echart_Test_1.html', 'r') # Echrt의 머릿글\n",
    "    input_2 = open('Echart_Test_2.html', 'r') # Echart의 끝글\n",
    "\n",
    "    # if Comp_Date_List in date_list :\n",
    "    #     Date_Index = date_list.index(Comp_Date_List[0])\n",
    "    #     # ---> ValueError: '2010.01.08' is not in list\n",
    "    #     # KOSPI/KODAQ date list : 2014.05.21\n",
    "    #     # print(\"# Index : %s\" % Date_Index)\n",
    "    #     # print(\"# Value : %s\" % date_list[Date_Index])\n",
    "    #     # print(\"Comp Closing list : %s\" % len(Comp_Closing_List))\n",
    "    #     for x in range(0, int(Date_Index)) :\n",
    "    #         # print(\"# %s번째 \" % x)\n",
    "    #         Comp_Closing_List.insert(0, \"0\") # 0번째에 넣은 리스트에 또 앞자리에 넣게된다. \n",
    "    # else :\n",
    "    #     print(\"date_list index : %s\" % date_list.index(\"2014.05.21\"))\n",
    "    #     Date_Index = Comp_Date_List.index(date_list.index(\"2014.05.21\"))\n",
    "    #     print(\"Date Index : %s\" % Date_Index)\n",
    "    #     del Comp_Closing_List[0:Date_Index]\n",
    "\n",
    "    closing_list_1 = KOSPI_List\n",
    "    closing_list_2 = KOSDAQ_List\n",
    "    closing_list_3 = Comp_Closing_List\n",
    "\n",
    "    # print(\"date list : %s\" % len(date_list))\n",
    "    # print(\"KOSPI list : %s\" % len(KOSPI_List))\n",
    "    # print(\"KOSDAQ list : %s\" % len(KOSDAQ_List))\n",
    "    # print(\"Comp Date list : %s\" % len(Comp_Date_List))\n",
    "    # print(\"Comp Closing list : %s\" % len(Comp_Closing_List))\n",
    "\n",
    "    output = open(File_Name, 'w+t')\n",
    "\n",
    "    print(\"# MAKE HTML Start\")\n",
    "    for line in input_1.readlines():\n",
    "        output.write(line)\n",
    "\n",
    "    output.write(\"          xAxis: {\\n\")\n",
    "    output.write(\"          data: \\n\")\n",
    "    output.write(\"[\")\n",
    "    for item in date_list:\n",
    "        output.write(\"'%s',\" % item)\n",
    "    output.write(\"]\")\n",
    "    output.write(\"\\n\")\n",
    "    output.write(\"          },\\n\")\n",
    "    output.write(\"          yAxis: {},\\n\")\n",
    "    output.write(\"          series: [\\n\")\n",
    "    if Dart_Market_Name == '코스피' :\n",
    "        output.write(\"          {\\n\")\n",
    "        output.write(\"              name: '%s',\\n\" % \"KOSPI\")\n",
    "        output.write(\"              type: '%s',\\n\" % \"line\")\n",
    "        output.write(\"              data: \")\n",
    "        output.write(\"[\")\n",
    "        for x in closing_list_1 :\n",
    "            output.write(\"'%s',\" % x)\n",
    "        output.write(\"]\")\n",
    "        output.write(\"              \\n\")\n",
    "        output.write(\"          },\\n\")\n",
    "    elif Dart_Market_Name == '코스닥' :\n",
    "        output.write(\"          {\\n\")\n",
    "        output.write(\"              name: '%s',\\n\" % \"KOSDAQ\")\n",
    "        output.write(\"              type: '%s',\\n\" % \"line\")\n",
    "        output.write(\"              data: \")\n",
    "        output.write(\"[\")\n",
    "        for x in closing_list_2 :\n",
    "            output.write(\"'%s',\" % x)\n",
    "        output.write(\"]\")\n",
    "        output.write(\"              \\n\")\n",
    "        output.write(\"          },\\n\")\n",
    "    else :\n",
    "        output.write(\"          {\\n\")\n",
    "        output.write(\"              name: '%s',\\n\" % \"KOSPI\")\n",
    "        output.write(\"              type: '%s',\\n\" % \"line\")\n",
    "        output.write(\"              data: \")\n",
    "        output.write(\"[\")\n",
    "        for x in closing_list_1 :\n",
    "            output.write(\"'%s',\" % x)\n",
    "        output.write(\"]\")\n",
    "        output.write(\"              \\n\")\n",
    "        output.write(\"          },\\n\")\n",
    "    output.write(\"          {\\n\")\n",
    "    output.write(\"              name: '%s',\\n\" % Dart_Comp_Name)\n",
    "    output.write(\"              type: '%s',\\n\" % \"line\")\n",
    "    output.write(\"              data: \")\n",
    "    output.write(\"[\")\n",
    "    for x in closing_list_3 :\n",
    "        output.write(\"'%s',\" % x)\n",
    "    output.write(\"]\")\n",
    "    output.write(\"              \\n\")\n",
    "    output.write(\"          },\\n\")\n",
    "\n",
    "    for line in input_2.readlines():\n",
    "        output.write(line)\n",
    "\n",
    "    print(\"# MAKE HTML Done\")\n",
    "\n",
    "    output.close()\n",
    "\n",
    "# def __New_Make_Chart (date_list, closing_list_A, closing_list_B) :\n",
    "def __New_Make_Chart (Dart_Exp_Code, Dart_Comp_Name, Market) :\n",
    "\n",
    "    DateTime = datetime.datetime.today().strftime(\"%Y%m%d_%H%M\")\n",
    "    File_Name = \"/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/Ananlyst_\"+Dart_Comp_Name+\"_\"+DateTime+\".html\"\n",
    "    print(File_Name)\n",
    "    input_1 = open('/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/New_Echart_Test_1.html', 'r') # Echrt의 머릿글\n",
    "\n",
    "    # 아래는 Make_Chart를 위한 조건들\n",
    "    Comp_Date_List, KOSPI_DATE_List, KOSDAQ_DATE_List = [], [], []\n",
    "    Comp_Closing_List, KOSPI_List, KOSDAQ_List = [], [], []\n",
    "\n",
    "    Exp_page = __Last_Page_Numb(Dart_Exp_Code)\n",
    "    Comp_Date_List, Comp_Closing_List = __Price_Find(Dart_Exp_Code, Exp_page)\n",
    "    date_list = Comp_Date_List\n",
    "\n",
    "    if Market == \"코스피\" :\n",
    "        KOSPI_Page = __Last_Page_Numb_Market(\"KOSPI\")\n",
    "        KOSPI_Date, KOSPI_List = __Market_Price(\"KOSPI\", KOSPI_Page)\n",
    "        closing_list_A = KOSPI_List\n",
    "        closing_list_B = Comp_Closing_List\n",
    "    elif Market == \"코스닥\" :\n",
    "        KOSDAQ_Page = __Last_Page_Numb_Market(\"KOSDAQ\")\n",
    "        KOSDAQ_Date, KOSDAQ_List = __Market_Price(\"KOSDAQ\", KOSDAQ_Page)\n",
    "        closing_list_A = KOSDAQ_List\n",
    "        closing_list_B = Comp_Closing_List\n",
    "\n",
    "    n = 200\n",
    "    del date_list[n:]\n",
    "    del closing_list_A[n:]\n",
    "    del closing_list_B[n:]\n",
    "    print(\"# After DEL\")\n",
    "    print(date_list[0])\n",
    "    print(closing_list_A[0])\n",
    "    print(closing_list_B[0])\n",
    "    output = open(File_Name, 'w+t')\n",
    "\n",
    "    print(\"# LENGTH\")\n",
    "    print(len(closing_list_A))\n",
    "    print(len(closing_list_B))\n",
    "\n",
    "    print(\"# Before replace\")\n",
    "    print(closing_list_A)\n",
    "    print(closing_list_B)\n",
    "\n",
    "    # ls = [type(item) for item in closing_list_A]\n",
    "    # print(ls) # ---> int\n",
    "    # ls = [type(item) for item in closing_list_B]\n",
    "    # print(ls) # ---> <class 'bs4.element.NavigableString'>\n",
    "    # 천 단위 , 자리수가 있으면 string이고 없으면 int 로 list 생성되는듯..\n",
    "\n",
    "    for idx, val in enumerate(closing_list_A) :\n",
    "        if type(closing_list_A[idx]) == int or type(closing_list_A[idx]) == float :\n",
    "            continue\n",
    "        else :\n",
    "            val = val.replace(\",\",\"\")\n",
    "            closing_list_A[idx] = val\n",
    "\n",
    "    for idx, val in enumerate(closing_list_B) :\n",
    "        if type(closing_list_B[idx]) == int or type(closing_list_B[idx]) == float :\n",
    "            continue\n",
    "        else :\n",
    "            val = val.replace(\",\",\"\")\n",
    "            closing_list_B[idx] = val\n",
    "\n",
    "    print(\"# after replace\")\n",
    "    print(closing_list_A)\n",
    "    print(closing_list_B)\n",
    "\n",
    "    # print(date_list.reverse()) # ---> None\n",
    "    # print(reversed(date_list)) # ---> <list_reverseiterator object at 0x12235bbb0>\n",
    "    # date_list.reverse() # ---> None\n",
    "    # print(reversed(date_list)) # ---> <list_reverseiterator object at 0x1190a7d00>\n",
    "    # print(date_list[::-1]) # ---> OK\n",
    "\n",
    "    # max_value_A = int(max(closing_list_A)) * 2\n",
    "    # max_value_B = int(max(closing_list_B)) * 2\n",
    "    numrow_A = [float(x) for x in closing_list_A]\n",
    "    max_value_A = int(max(numrow_A)) * 1.5\n",
    "    numrow_B = [float(x) for x in closing_list_B]\n",
    "    max_value_B = int(max(numrow_B)) * 1.5 # ---> ValueError: could not convert string to float: '11,550'\n",
    "\n",
    "    print(\"# MAKE HTML Start\")\n",
    "    for line in input_1.readlines():\n",
    "        output.write(line)\n",
    "    output.write(\"        data: ['%s', '%s']\\n\" % (Market, Dart_Comp_Name))\n",
    "    output.write(\"    },\\n\")\n",
    "    output.write(\"    xAxis: [\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            type: 'category',\\n\")\n",
    "    output.write(\"            axisTick: {\\n\")\n",
    "    output.write(\"                alignWithLabel: true\\n\")\n",
    "    output.write(\"            },\\n\")\n",
    "    output.write(\"            data: [\")\n",
    "    for item in date_list[::-1] :\n",
    "        output.write(\"'%s',\" % item)\n",
    "    output.write(\"        ]\\n\")\n",
    "    output.write(\"        }\\n\")\n",
    "    output.write(\"    ],\\n\")\n",
    "    output.write(\"    yAxis: [\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            type: 'value',\\n\")\n",
    "    output.write(\"            name: '%s',\\n\" % Market)\n",
    "    output.write(\"            min: 0,\\n\")\n",
    "    output.write(\"            max: %s,\\n\" % str(max_value_A))\n",
    "    output.write(\"            position: 'right',\\n\")\n",
    "    output.write(\"            axisLine: {\\n\")\n",
    "    output.write(\"                lineStyle: {\\n\")\n",
    "    output.write(\"                    color: colors[0]\\n\")\n",
    "    output.write(\"                }\\n\")\n",
    "    output.write(\"            },\\n\")\n",
    "    output.write(\"            axisLabel: {\\n\")\n",
    "    output.write(\"                formatter: '{value} 원'\\n\")\n",
    "    output.write(\"            }\\n\")\n",
    "    output.write(\"        },\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            type: 'value',\\n\")\n",
    "    output.write(\"            name: '%s',\\n\" % Dart_Comp_Name)\n",
    "    output.write(\"            min: 0,\\n\")\n",
    "    output.write(\"            max: %s,\\n\" % str(max_value_B))\n",
    "    output.write(\"            position: 'left',\\n\")\n",
    "    output.write(\"            axisLine: {\\n\")\n",
    "    output.write(\"                lineStyle: {\\n\")\n",
    "    output.write(\"                    color: colors[1]\\n\")\n",
    "    output.write(\"                }\\n\")\n",
    "    output.write(\"            },\\n\")\n",
    "    output.write(\"            axisLabel: {\\n\")\n",
    "    output.write(\"                formatter: '{value} 원'\\n\")\n",
    "    output.write(\"            }\\n\")\n",
    "    output.write(\"        }\\n\")\n",
    "    output.write(\"    ],\\n\")\n",
    "    output.write(\"    series: [\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            name: '우선주',\\n\")\n",
    "    output.write(\"            type: 'line',\\n\")\n",
    "    output.write(\"              data: [\\n\")\n",
    "    for x in closing_list_A[::-1] :\n",
    "        output.write(\"'%s',\" % x)\n",
    "    output.write(\"        ]\\n\")\n",
    "    output.write(\"        },\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            name: '보통주',\\n\")\n",
    "    output.write(\"            type: 'line',\\n\")\n",
    "    output.write(\"            yAxisIndex: 1,\\n\")\n",
    "    output.write(\"              data: [\\n\")\n",
    "    for x in closing_list_B[::-1]  :\n",
    "        output.write(\"'%s',\" % x)\n",
    "    output.write(\"    ]\\n\")\n",
    "    output.write(\"        }\\n\")\n",
    "    output.write(\"    ]\\n\")\n",
    "    output.write(\"};\\n\")\n",
    "    output.write(\"        // use configuration item and data specified to show chart\\n\")\n",
    "    output.write(\"        myChart.setOption(option);\\n\")\n",
    "    output.write(\"    </script>\\n\")\n",
    "    output.write(\"</body>\\n\")\n",
    "\n",
    "    # for line in input_2.readlines():\n",
    "        # output.write(line)\n",
    "\n",
    "    print(\"# MAKE HTML Done\")\n",
    "\n",
    "    output.close()\n",
    "\n",
    "def __Naver_Research(Dart_Comp_Name) :\n",
    "\n",
    "    File_Name_1 = \"/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/Naver_Reports_Subject.txt\"\n",
    "    File_Name_2 = \"/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/Naver_Reports_Files.txt\"\n",
    "    Date_Check = datetime.datetime.today().strftime(\"%y.%m.%d\")\n",
    "    print(\"Date_Check\")\n",
    "    print(Date_Check)\n",
    "\n",
    "    f = open(File_Name_1, \"r\")\n",
    "    searchlines = f.readlines()\n",
    "    f.close()\n",
    "    for i, line in enumerate(searchlines):\n",
    "        print(\"# %s 라인 : %s\" % (i, line))\n",
    "        if Date_Check in line and i == 0 :\n",
    "            print(\"# 오늘....\")\n",
    "            print(\"# %s 라인 : %s\" % (i, line))\n",
    "        # 1    대양전기공업                       수소차로 상륙하다     교보증권 NaN  21.01.20   3879.0\n",
    "    return 0\n",
    "\n",
    "    output_1 = open(File_Name_1, 'a+t')\n",
    "    output_2 = open(File_Name_2, 'a+t')\n",
    "\n",
    "    url = \"https://finance.naver.com/research/company_list.nhn\"\n",
    "\n",
    "    html = urlopen(url, context=context)\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    main_pages = bs_object.find_all(\"a\")\n",
    "\n",
    "    for a_list in main_pages:\n",
    "        # print(\"############\")\n",
    "        last_page=a_list.attrs['href']\n",
    "        if \"company_list.nhn?&page=\" in last_page :\n",
    "            object=last_page.split('=')\n",
    "            page_max = object[1]\n",
    "\n",
    "    Report_Total = pd.DataFrame()\n",
    "    for page_num in range(1, int(page_max)) :\n",
    "    # for page_num in range(1, 30) :\n",
    "\n",
    "        url = \"https://finance.naver.com/research/company_list.nhn?&page=\" + str(page_num)\n",
    "        # print(url)\n",
    "\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                                'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                                'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "                'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "                'Accept-Encoding': 'none', \\\n",
    "                'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "                'Connection': 'keep-alive'}\n",
    "        req = Request(url=url, headers=headers)\n",
    "\n",
    "        try :\n",
    "            html = urlopen(req).read()\n",
    "            # html = urlopen(url, context=context)\n",
    "        except HTTPError as err:\n",
    "            if err.code == 404 :\n",
    "                print(\"# Error HTTP : 404\")\n",
    "                return\n",
    "            elif err.code == 403 :\n",
    "                print(\"# Error HTTP : 403\")\n",
    "                return\n",
    "            elif err.code == 500 :\n",
    "                print(\"# Error HTTP : 500\")\n",
    "                return\n",
    "            elif err.code == 505:\n",
    "                print(\"# Error HTTP : 505\")\n",
    "                return\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        table = bs_object.find('div', {'class':'box_type_m'})\n",
    "        file_table = table.find_all('td', {'class':'file'}) # ---> find로하면 첫번째만 검색\n",
    "\n",
    "        # ---> TypeError: 'NoneType' object is not subscriptable\n",
    "        File_DF = pd.DataFrame()\n",
    "        File_List = []\n",
    "        # File_SR = pd.Series() # ---> DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
    "        # print(type(file_table)) # ---> find <class 'bs4.element.Tag'>, find_all <class 'bs4.element.ResultSet'>\n",
    "        # print(file_table)\n",
    "        for a_list in file_table : \n",
    "            # print(\"# a_list : %s, %s\" % (a_list, type(a_list))) # ---> # a_list : <td class=\"file\"></td>, <class 'bs4.element.Tag'>\n",
    "            try:\n",
    "                file_link = a_list.find(\"a\")[\"href\"]\n",
    "                File_List.append(file_link)\n",
    "                # print(\"# file_list : %s\" % file_link) # --->             # TypeError: 'NoneType' object is not subscriptable\n",
    "            except TypeError:\n",
    "                File_List.append(\"N/A\")\n",
    "                pass\n",
    "\n",
    "            # print(file_link)\n",
    "            # file_link = pd.Series(a_list.find(\"a\")[\"href\"]) # ---> Series로 넣을 때 잘린다..\n",
    "\n",
    "            # File_List.append(file_link)\n",
    "\n",
    "            # File_SR.append(file_link)\n",
    "            # print(type(file_link))\n",
    "            # print(file_link)\n",
    "            # last_page=a_list.attrs['href']\n",
    "            # print(last_page)\n",
    "            # File_DF.insert(0, 'file_link', file_link)\n",
    "            # TypeError: cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid\n",
    "        # print(\"# for END\")\n",
    "        # print(File_List)\n",
    "        # print(len(File_List))\n",
    "        # file_data = pd.read_html(str(file_table), header=0) # ---> ValueError: No tables found\n",
    "        # print(type(file_table)) # ---> <class 'bs4.element.Tag'>\n",
    "        # print(\"############3 file_DF\")\n",
    "        # print(File_DF)\n",
    "\n",
    "        table_data = pd.read_html(str(table), header=0) # ---> pd.read_html은 List 형태로 보내고 그 안에 DataFrame\n",
    "        Report_Data = table_data[0] # ---> [1] 일 경우는 하단의 페이지 번호가 출력\n",
    "        Report_Data.dropna(subset=['종목명'], inplace=True)\n",
    "        # Report_Data[\"레포트\"] = File_List\n",
    "        # print(type(Report_Data)) # ---> <class 'pandas.core.frame.DataFrame'>\n",
    "        print(Report_Data.iloc[Report_Data['첨부']==Date_Check])\n",
    "\n",
    "        sales_3_value = html_json.loc[html_json['account_nm']=='매출액', ['bfefrmtrm_amount']].values[0]\n",
    "        # print(\"########################## 레포트 추가 FOR ############################1\")\n",
    "        # print(Report_Total.shape) # ---> (0, 0)\n",
    "        Report_Total.append(Report_Data, ignore_index = True)\n",
    "        # print(Report_Total.shape) # ---> (0, 0)\n",
    "        # print(\"########################## 레포트 추가 FOR ############################2\")\n",
    "        # print(Report_Data)\n",
    "        output_1.write(Report_Data.to_string(header=False, index=True))\n",
    "        output_1.write(\"\\n\")\n",
    "        # Report_Total.to_csv(File_Name_1, mode='a', sep='\\t', encoding='utf-8')\n",
    "        # np.savetxt(r'File_Name_1', Report_Total.values, fmt='%d')\n",
    "        # output_1.write(Report_Table.to_string())\n",
    "        # print(File_List)\n",
    "        for idx, file_write in enumerate(File_List) :\n",
    "            output_2.write(\"%s\\t%s\\n\" % (idx, file_write))\n",
    "\n",
    "    print(\"########################## 모든 레포트 ############################5\")\n",
    "\n",
    "    # output.write(File_List) # ---> TypeError: write() argument must be str, not list\n",
    "    output.close()\n",
    "\n",
    "    # File_Name_1 = \"/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/Naver_Reports_Subject.txt\"\n",
    "    # File_Name_2 = \"/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/Naver_Reports_Files.txt\"\n",
    "\n",
    "    f = open(File_Name_1, \"r\")\n",
    "    searchlines = f.readlines()\n",
    "    f.close()\n",
    "    print(Dart_Comp_Name)\n",
    "    Subject_line = -1 # ---> list든 file read든 0부터 시작이니 -1로 미리 선언\n",
    "    Subject_line_List = [] # ---> 레포트가 다수일 경우 리스트를 해야한다.\n",
    "    for i, line in enumerate(searchlines):\n",
    "        if Dart_Comp_Name in line: # 라인에 회사이름과 라인넘버가 같으면 있는 것으로 간주\n",
    "            print(\"# %s 라인 : %s\" % (i, line))\n",
    "            # Subject_line = i\n",
    "            Subject_line_List.append(i)\n",
    "\n",
    "    f = open(File_Name_2, \"r\")\n",
    "    searchlines = f.readlines()\n",
    "    f.close()\n",
    "    for i, line in enumerate(searchlines):\n",
    "        # if Subject_line == i : # dnl\n",
    "        if i in Subject_line_List :\n",
    "            print(\"# %s 라인 : %s\" % (i, line))\n",
    "\n",
    "def __Google_Upload():\n",
    "\n",
    "    creds = None\n",
    "\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "\n",
    "    service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "    _Name = datetime.datetime.today().strftime(\"_%Y%m%d\")\n",
    "\n",
    "    Upload_File_List = [File_Name]\n",
    "    print(Upload_File_List)\n",
    "    \n",
    "    for file_name in Upload_File_List :\n",
    "        print(\"Upload File : %s\" % file_name)\n",
    "        file_metadata = {'name': file_name, 'parents' : ['18BXSAPuOYhd_P0DGIdwLbLCW7XNPcAZh']}\n",
    "        media = MediaFileUpload(file_name, resumable=True) # mimetype은 자동으로 정의해주므로 삭제\n",
    "        file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "        print(\"# File ID: %s\" % file.get('id'))\n",
    "\n",
    "def __MENU() : \n",
    "    print(\"\")\n",
    "    print(\"##############################\")\n",
    "    print(\"# Choice Company Order : 0 ~ 9\")\n",
    "    print(\"\")\n",
    "    input_V = input()\n",
    "    return input_V\n",
    "\n",
    "if(__name__ == '__main__') :\n",
    "    print(\"############################################################\")\n",
    "    print(\"# Program Start\")\n",
    "    print(\"############################################################\")\n",
    "\n",
    "    BEGIN_DATE = \"20100101\"\n",
    "    ROE_Min = 20\n",
    "    # PER_Min, PER_Max = 1, 10\n",
    "    PER_Min, PER_Max = 1, 20\n",
    "    TOP_No = 30\n",
    "    print(\"############################################################\")\n",
    "    print(\"# ROE_Min = %s\" % ROE_Min)\n",
    "    print(\"# PER_Min, PER_Max = %s, %s\" % (PER_Min, PER_Max))\n",
    "    print(\"############################################################\")\n",
    "\n",
    "    TEST_Go = 0\n",
    "    # TEST_Go = 1 # 밑에 것들만 TEST\n",
    "    \n",
    "    if TEST_Go != 1 :\n",
    "        Result_Comp = pd.DataFrame()\n",
    "        for Market in range(1,3): # KOSPI, KOSDAQ 을 각각 네이버에서 호출하여 Result_Comp로 합친다\n",
    "        # for x in range(1,2):\n",
    "            Get_Comp = __Get_Result(Market, ROE_Min)\n",
    "            Result_Comp = Result_Comp.append(Get_Comp)\n",
    "            # print(Result_Comp)\n",
    "            ################## 여기서 무언가 없어진다.......................\n",
    "\n",
    "        # 이전에서 안된 ROE, PER 조건을 다시 주고 Sorting 도 다시 시행\n",
    "        # Sorting을 다시해서 KOSPI&KOSDAQ 섞어서 Sorting됨 ---> KOSPI가 찾기 어려워지는...ㅠ\n",
    "        Result_Comp = Result_Comp.loc[(Result_Comp['ROE'] >= ROE_Min)]\n",
    "        Result_Comp = Result_Comp.loc[(Result_Comp['PER'] > PER_Min)&(Result_Comp['PER'] < PER_Max)]\n",
    "        Result_Comp = Result_Comp.sort_values(by=['ROE'], ascending=False)\n",
    "\n",
    "        # print(\"# Result_Comp\")\n",
    "        # print(Result_Comp)\n",
    "\n",
    "    Corp_DF =  __get_XML()\n",
    "    # print(Corp_DF[Corp_DF['corp_name']==\"삼성전자\"])\n",
    "    # print(Corp_DF[Corp_DF['corp_name']==\"삼성전자\"].values)\n",
    "    # print(Corp_DF[Corp_DF['corp_name']==\"삼성전자\"].values[0])\n",
    "    # print(Corp_DF.loc[Corp_DF.corp_name==\"한솔케미칼\",'stock_code'].values[0])\n",
    "    # print(Corp_DF.loc[Corp_DF.corp_name==\"교촌에프앤비\",'stock_code'].values[0])\n",
    "\n",
    "    Result_Comp_New = pd.DataFrame()\n",
    "    Result_PBR_List = []\n",
    "    if TEST_Go != 1 :\n",
    "        for index, row in Result_Comp.iterrows():\n",
    "            # row_expcode = Corp_DF.loc[Corp_DF.corp_name==row['회사명'],'stock_code'].values\n",
    "            # row_expcode = Corp_DF.loc[Corp_DF.corp_name==row['회사명'],'stock_code'].values[0]\n",
    "            # ---> IndexError: index 0 is out of bounds for axis 0 with size 0\n",
    "            # ---> 화승인더\n",
    "            # ---> Empty DataFrame\n",
    "            row_test = Corp_DF.loc[Corp_DF.corp_name==row['회사명']]\n",
    "            if row_test.empty :\n",
    "            # if row_expcode.empty : # ---> AttributeError: 'str' object has no attribute 'empty'\n",
    "            # if row_expcode == '' :\n",
    "                # print(\"DataFrame is empty! : %s \" % row['회사명'])\n",
    "                continue\n",
    "            else :\n",
    "                # print(\"회사명 : %s , %s, %s\" % (row['회사명'], Corp_DF.loc[Corp_DF.corp_name==row['회사명'],'stock_code'].values[0], Corp_DF.loc[Corp_DF.corp_name==row['회사명'],'corp_code'].values[0]))\n",
    "                # print(Corp_DF.loc[Corp_DF.corp_name==row['회사명'],'stock_code'].values[0])\n",
    "                # print(Corp_DF.loc[Corp_DF.corp_name==row['회사명'],'corp_code'].values[0])\n",
    "                row_expcode = Corp_DF.loc[Corp_DF.corp_name==row['회사명'],'stock_code'].values[0]\n",
    "                row_corpcode = Corp_DF.loc[Corp_DF.corp_name==row['회사명'],'corp_code'].values[0]\n",
    "                Result_Comp.loc[index,'expcode'] = row_expcode\n",
    "                Result_Comp.loc[index,'corpcode'] = row_corpcode\n",
    "                # print(row['회사명'], row['ROE'], row['PER'], row['외국인비율'], row['Market'], row_expcode, row_corpcode)\n",
    "                # 이상하게 여기서는 정상이지만 여기 for문과 if문을 빠져나가면 XML 하고 맞춘 코드가 엉망이 된다...ㅠㅠ\n",
    "                # 그래서 DataFrame 다시 생성...\n",
    "                new_row = {'회사명':row['회사명'], 'ROE':row['ROE'], 'PER':row['PER'], '외국인비율':row['외국인비율'], 'Market':row['Market'] , 'expcode':row_expcode, 'corpcode':row_corpcode}\n",
    "                Result_Comp_New = Result_Comp_New.append(new_row, ignore_index=True)\n",
    "\n",
    "        for index, row in Result_Comp.iterrows():\n",
    "            Result_PBR = __Naver_Inst_Anal(row['expcode'])\n",
    "            Result_PBR_List.append(Result_PBR)\n",
    "        Result_Comp_New['PBR'] = Result_PBR_List\n",
    "\n",
    "    if TEST_Go != 1 :\n",
    "        print(\"############################################################\")\n",
    "        print(\"# FULL List ---> 생략\")\n",
    "        # print(Result_Comp)\n",
    "        # print(Result_Comp_New[['회사명', 'ROE', 'PER', '외국인비율', 'Market', 'expcode', 'corpcode']])\n",
    "\n",
    "        print(\"############################################################\")\n",
    "        print(\"# TOP 30\")\n",
    "        print(\"# ROE_Min = %s\" % ROE_Min)\n",
    "        print(\"# PER_Min, PER_Max = %s, %s\" % (PER_Min, PER_Max))\n",
    "        print(\"############################################################\")\n",
    "        # print(Result_Comp.head(TOP_No))\n",
    "        print(Result_Comp_New[['회사명', 'ROE', 'PER', 'PBR', '외국인비율', 'Market', 'expcode', 'corpcode']].head(TOP_No))\n",
    "        print(\"############################################################\")\n",
    "        print(\"\")\n",
    "\n",
    "    # Dart_Corp_Code = str(Result_Comp_New[['corpcode']].head(1).replace(\" \", \"\"))\n",
    "    # Dart_Exp_Code = str(Result_Comp_New[['expcode']].head(1).replace(\" \", \"\"))\n",
    "\n",
    "    if TEST_Go != 1 :\n",
    "        loop = 1\n",
    "        while loop == 1:\n",
    "            Choice_Comp = __MENU()\n",
    "            # print(Choice_Comp)\n",
    "            print(type(Choice_Comp))\n",
    "            print(\"# 다시 시작...\")\n",
    "            if Choice_Comp.isdigit() :\n",
    "                Comp_Name = Result_Comp_New['회사명'].iloc[int(Choice_Comp)]\n",
    "                DateTime = datetime.datetime.today().strftime(\"%Y%m%d_%H%M\")\n",
    "                File_Name = \"/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/Ananlyst_\"+Comp_Name+\"_\"+DateTime+\".txt\"\n",
    "                output = open(File_Name, 'a+t')\n",
    "\n",
    "                print(\"############################################################\")\n",
    "                output.write(\"############################################################\\n\")\n",
    "                print(Result_Comp_New[['회사명', 'ROE', 'PER', 'PBR', '외국인비율', 'Market', 'expcode', 'corpcode']].head(TOP_No))\n",
    "                output.write(\"%s\\n\" % Result_Comp_New[['회사명', 'ROE', 'PER', 'PBR', '외국인비율', 'Market', 'expcode', 'corpcode']].head(TOP_No))\n",
    "                print(\"############################################################\")\n",
    "                output.write(\"############################################################\\n\")\n",
    "\n",
    "                output.write(\"############################################################\\n\")\n",
    "                print(\"# 기업명 : %s \" % Result_Comp_New['회사명'].iloc[int(Choice_Comp)])\n",
    "                output.write(\"# 기업명 : %s \\n\" % Result_Comp_New['회사명'].iloc[int(Choice_Comp)])\n",
    "                print(\"############################################################\")\n",
    "                output.write(\"############################################################\\n\")\n",
    "                output.write(\"\\n\")\n",
    "                output.close() # ---> 아래부터는 각 function에서 열고 닫는다\n",
    "\n",
    "\n",
    "                Dart_Exp_Code = Result_Comp_New['expcode'].iloc[int(Choice_Comp)]\n",
    "                Dart_Corp_Code = Result_Comp_New['corpcode'].iloc[int(Choice_Comp)]\n",
    "                Dart_Comp_Name = Result_Comp_New['회사명'].iloc[int(Choice_Comp)]\n",
    "                Dart_Market_Name = Result_Comp_New['Market'].iloc[int(Choice_Comp)]\n",
    "\n",
    "                #  교촌, 미스터블루 오류나고 있음....\n",
    "                __Naver_CompInfo(Dart_Corp_Code, Dart_Exp_Code, File_Name)\n",
    "                __Naver_BusinessType(Dart_Exp_Code, File_Name)\n",
    "                __Naver_Anal(Dart_Exp_Code, File_Name)\n",
    "                # tail_1 = __Dart_Search_List(Dart_Corp_Code, Dart_Exp_Code, File_Name)\n",
    "                # input_rcept_no = tail_1.rcept_no.item()\n",
    "\n",
    "                # __Dart_Search_1st(Dart_Corp_Code, Dart_Exp_Code, File_Name)\n",
    "                # __Dart_Search_1st_Diff(Dart_Corp_Code, Dart_Exp_Code, File_Name)\n",
    "                # __Dart_Search_Stock(Dart_Corp_Code, Dart_Exp_Code, File_Name)\n",
    "                # __Dart_Search_Emp(Dart_Corp_Code, Dart_Exp_Code, File_Name)\n",
    "                # __Dart_Search_Report(Dart_Corp_Code, Dart_Exp_Code, File_Name)\n",
    "                # __Dart_Search_Report_Detail(Dart_Corp_Code, Dart_Exp_Code, File_Name) # 현금흐름표\n",
    "                # __Dart_Search_Attention(Dart_Corp_Code, Dart_Exp_Code, File_Name, input_rcept_no)\n",
    "\n",
    "                # if Result_Comp_New['Market'].iloc[int(Choice_Comp)] == \"코스피\" :\n",
    "                #     __New_Make_Chart(Dart_Exp_Code, Dart_Comp_Name, \"코스피\")\n",
    "                # elif Result_Comp_New['Market'].iloc[int(Choice_Comp)] == \"코스닥\" :\n",
    "                #     __New_Make_Chart(Dart_Exp_Code, Dart_Comp_Name, \"코스닥\")\n",
    "                # else :\n",
    "                #     print(\"# Make Chart Error\")\n",
    "                # __New_Make_Chart(date_list_A, closing_list_A, closing_list_B)\n",
    "                # __Last_Page_Numb(\"339770\")\n",
    "                # __Last_Page_Numb_Market(\"KOSPI\")\n",
    "\n",
    "                print(\"# Naver Research Report\")\n",
    "                __Naver_Research(Dart_Comp_Name)\n",
    "                # __Google_Upload(File_Name)\n",
    "\n",
    "            else :\n",
    "                print(\"# NOT Digit\")\n",
    "                break\n",
    "\n",
    "    # File_Name = \"/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/test.txt\"\n",
    "\n",
    "    print(\"# Program End\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
