{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "    // AUTORUN ALL CELLS ON NOTEBOOK-LOAD!\n",
       "    require(\n",
       "        ['base/js/namespace', 'jquery'], \n",
       "        function(jupyter, $) {\n",
       "            $(jupyter.events).on(\"kernel_ready.Kernel\", function () {\n",
       "                console.log(\"Auto-running all cells-below...\");\n",
       "                jupyter.actions.call('jupyter-notebook:run-all-cells-below');\n",
       "                jupyter.actions.call('jupyter-notebook:save-notebook');\n",
       "            });\n",
       "        }\n",
       "    );\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<script>\n",
    "    // AUTORUN ALL CELLS ON NOTEBOOK-LOAD!\n",
    "    require(\n",
    "        ['base/js/namespace', 'jquery'], \n",
    "        function(jupyter, $) {\n",
    "            $(jupyter.events).on(\"kernel_ready.Kernel\", function () {\n",
    "                console.log(\"Auto-running all cells-below...\");\n",
    "                jupyter.actions.call('jupyter-notebook:run-all-cells-below');\n",
    "                jupyter.actions.call('jupyter-notebook:save-notebook');\n",
    "            });\n",
    "        }\n",
    "    );\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market : https://finance.naver.com/sise/sise_index_day.nhn?code=KOSPI&page=1\n",
      "# Market Page_Number :  1359\n",
      "# KOSPI Page : 1359\n",
      "# Company : KOSPI\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d6459580190c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[0mKOSPI_Page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__Last_Page_Numb_Market\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"KOSPI\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"# KOSPI Page : %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mKOSPI_Page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m     \u001b[0mKOSPI_Date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKOSPI_List\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__Market_Price\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"KOSPI\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKOSPI_Page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[1;31m# print(\"# KOSPI DATE\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-d6459580190c>\u001b[0m in \u001b[0;36m__Market_Price\u001b[1;34m(company_code, page)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0murl_main\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://finance.naver.com/sise/sise_index_day.nhn?code=\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcompany_code\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"&page=\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;31m# print(\"# url : %s\" % url_main)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mcode_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_main\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# ---> code data로 출력을 생성하면 NaN이 1개라인이 남음, Type은 <class 'list'>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[0mdf_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_main\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# ---> List 로 append, 본문[0]과 페이지 출력[1] 부분 중 본문을 출력\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\All Users\\Anaconda3\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m         \u001b[0mkeep_default_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_default_na\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m         \u001b[0mdisplayed_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisplayed_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m     )\n",
      "\u001b[1;32mC:\\Users\\All Users\\Anaconda3\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m             \u001b[0mtables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_tables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcaught\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m             \u001b[1;31m# if `io` is an io-like object, check if it's seekable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\All Users\\Anaconda3\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36mparse_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparsed\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfooter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mtuples\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \"\"\"\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mtables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_tables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_thead_tbody_tfoot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtable\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\All Users\\Anaconda3\\lib\\site-packages\\pandas\\io\\html.py\u001b[0m in \u001b[0;36m_build_doc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m                 \u001b[1;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    715\u001b[0m                     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\All Users\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 543\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[1;32m-> 1362\u001b[1;33m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m         \u001b[1;31m# will parse host:port\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1287\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhttp_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttp_conn_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1288\u001b[0m         \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_debuglevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_debuglevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, host, port, key_file, cert_file, timeout, source_address, context, check_hostname, blocksize)\u001b[0m\n\u001b[0;32m   1389\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcert_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcert_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1391\u001b[1;33m                 \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_default_https_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1392\u001b[0m                 \u001b[1;31m# enable PHA for TLS 1.3 connections if available\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_handshake_auth\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mcreate_default_context\u001b[1;34m(purpose, cafile, capath, cadata)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;31m# CERT_OPTIONAL or CERT_REQUIRED. Let's try to load default system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# root CA certificates for the given purpose. This may fail silently.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m         \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_default_certs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpurpose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mload_default_certs\u001b[1;34m(self, purpose)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"win32\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mstorename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_windows_cert_stores\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_windows_store_certs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpurpose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_default_verify_paths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.error import HTTPError\n",
    "from urllib.parse import quote\n",
    "from matplotlib import pyplot as plt\n",
    "from sys import platform\n",
    "import bs4, ssl\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime, time # for sleep\n",
    "import requests\n",
    "import numpy as np\n",
    "import io\n",
    "import codecs\n",
    "\n",
    "import xml.etree.ElementTree as et \n",
    "\n",
    "import json\n",
    "import urllib\n",
    "import urllib.request\n",
    "import sys\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                            'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                            'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "            'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "            'Accept-Encoding': 'none', \\\n",
    "            'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "            'Connection': 'keep-alive'}\n",
    "\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "############################################################\n",
    "def __Last_Page_Find(i, Market) :\n",
    "    # print(\"# Last_Page_Find Start\")\n",
    "    if Market == 1 :\n",
    "        url = \"https://finance.naver.com/sise/sise_market_sum.nhn?&page=\" + str(i)\n",
    "    else :\n",
    "        url = \"https://finance.naver.com/sise/sise_market_sum.nhn?sosok=1&page=\" + str(i)\n",
    "    # print(\"# print URL\")\n",
    "    # print(url) # ---> 당시의 위치정보를 기반으로 15페이지 가져오는 듯, 어찌 가져오는지는 모르겠음...(2020.05.21)\n",
    "    # ---> HTTP Error 403: Forbidden\n",
    "    # headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\n",
    "    # req = Request(url=url, headers={'User-Agent': 'Mozilla/5.0', 'referer': 'http://m.naver.com'})\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                             'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                             'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "               'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "               'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "               'Accept-Encoding': 'none', \\\n",
    "               'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "               'Connection': 'keep-alive'}\n",
    "    req = Request(url=url, headers=headers)\n",
    "\n",
    "    try :\n",
    "        html = urlopen(req).read()\n",
    "        # html = urlopen(url, context=context)\n",
    "    except HTTPError as err:\n",
    "        if err.code == 404 :\n",
    "            print(\"# Error HTTP : 404\")\n",
    "            return\n",
    "        elif err.code == 403 :\n",
    "            print(\"# Error HTTP : 403\")\n",
    "            return\n",
    "        elif err.code == 500 :\n",
    "            print(\"# Error HTTP : 500\")\n",
    "            return\n",
    "        elif err.code == 505:\n",
    "            print(\"# Error HTTP : 505\")\n",
    "            return\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    # test = bs_object.find('table' ,attrs={'class':'type_2'})\n",
    "    # numbersss = test.findAll(\"td\", {\"class\": \"number\"})\n",
    "    # print(numbersss)\n",
    "\n",
    "    data = []\n",
    "    table = bs_object.find('table', attrs={'class':'type_2'})\n",
    "    table_body = table.find('tbody')\n",
    "    rows = table_body.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "    # print(\"##################\")\n",
    "    # for x in data :\n",
    "        # print(x)\n",
    "\n",
    "    # print(\"##########################################\")\n",
    "    # print(type(data))\n",
    "    Data_DF = pd.DataFrame(data, columns=['No','회사명','현재가','전일비','등락률','액면가','시가총액','상장주식수','외국인비율','거래량','PER','ROE'])\n",
    "    # print(type(data_df))\n",
    "    # print(data_df)\n",
    "    # print(\"# Drop NA\")\n",
    "    Data_DF = Data_DF.dropna()\n",
    "    Data_DF = Data_DF[['No','회사명','ROE','PER','외국인비율','현재가']]\n",
    "    if Market == 1 :\n",
    "        Data_DF['Market'] = \"코스피\"\n",
    "    else :\n",
    "        Data_DF['Market'] = \"코스닥\"\n",
    "\n",
    "    return Data_DF\n",
    "\n",
    "############################################################\n",
    "def __Last_Page_Numb(company_code, dist) :\n",
    "\n",
    "    if dist == 1 :\n",
    "        url = \"https://finance.naver.com/item/sise_day.nhn?code=\" + company_code\n",
    "    else :\n",
    "        url = \"https://finance.naver.com/research/company_list.nhn?searchType=itemCode&itemCode=\" + company_code\n",
    "    \n",
    "    print(url)\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "        'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "        'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "        'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "        'Accept-Encoding': 'none', \\\n",
    "        'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "        'Connection': 'keep-alive'}\n",
    "\n",
    "    req = Request(url=url, headers=headers)\n",
    "    html = urlopen(req).read()\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    table = bs_object.find('td', attrs={'class':'pgRR'})\n",
    "    if table is None :\n",
    "        print(\"# Naver Report 없음\")\n",
    "        return 10000\n",
    "\n",
    "    print(table)\n",
    "\n",
    "    for x in table.find_all('a') :\n",
    "        test = x['href']\n",
    "        active = test.split(\"=\")\n",
    "        if dist == 1 :\n",
    "            page_num = active[2]\n",
    "        else :\n",
    "            page_num = active[3]\n",
    "\n",
    "    if dist == 1 :\n",
    "        print(\"# Company Page_Number : \", page_num)\n",
    "    else :\n",
    "        print(\"# Report Page_Number : \", page_num)\n",
    "\n",
    "    return page_num\n",
    "############################################################\n",
    "def __Last_Page_Numb_Market(Market) :\n",
    "    if Market == \"KOSPI\" :\n",
    "        url = \"https://finance.naver.com/sise/sise_index_day.nhn?code=KOSPI&page=1\"\n",
    "        # print(url)\n",
    "    elif Market == \"KOSDAQ\" :\n",
    "        url = \"https://finance.naver.com/sise/sise_index_day.nhn?code=KOSDAQ&page=1\"\n",
    "        # print(url)\n",
    "    print(\"Market : %s\" % url)\n",
    "\n",
    "    html = urlopen(url, context=context)\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    main1_pages = bs_object.find_all(\"a\")\n",
    "    for a_list in main1_pages:\n",
    "        if a_list is main1_pages[-1] :\n",
    "            last_page=a_list.attrs['href']\n",
    "        else :\n",
    "            continue\n",
    "        page_num: object=last_page.split('=')\n",
    "        print(\"# Market Page_Number : \", page_num[2])\n",
    "        return page_num[2]\n",
    "\n",
    "############################################################\n",
    "def __Price_Find(company_code, page):\n",
    "    page = int(page)\n",
    "    df_list, date_list, closing_list, gap_list, gap_perf  = [], [], [], [], []\n",
    "\n",
    "    date_list, closing_list = [], []\n",
    "    for page_num in range(1, page) :\n",
    "    # for page_num in range(1, 125) : # ---> 1페이지 당 10일, 250일이 년중 평일이라 하면 25페이지가 1년, 125페이지가 5년.\n",
    "        url= \"https://finance.naver.com/item/sise_day.nhn?code=\" + company_code + \"&page=\" + str(page_num)\n",
    "        print(url)\n",
    "\n",
    "        req = Request(url=url, headers=headers)\n",
    "\n",
    "        try :\n",
    "            html = urlopen(req).read()\n",
    "            # html = urlopen(url, context=context)\n",
    "        except HTTPError as err:\n",
    "            if err.code == 404 :\n",
    "                print(\"# Error HTTP : 404\")\n",
    "                return\n",
    "            elif err.code == 403 :\n",
    "                print(\"# Error HTTP : 403\")\n",
    "                return\n",
    "            elif err.code == 500 :\n",
    "                print(\"# Error HTTP : 500\")\n",
    "                return\n",
    "            elif err.code == 505:\n",
    "                print(\"# Error HTTP : 505\")\n",
    "                return\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "        table = bs_object.find('table', attrs={'class':'type2'})\n",
    "        table_body = table.find_all('td', attrs={'class':'num'})\n",
    "        date_body = table.find_all('span', attrs={'class':'tah p10 gray03'})\n",
    "\n",
    "        for x in date_body :\n",
    "            # print(\"x.contents type : %s\" % type(x.contents)) # ---> x.contents type : <class 'list'>\n",
    "            date_list.append(x.contents[0])\n",
    "\n",
    "        testlist = []\n",
    "        for tr in table_body :\n",
    "            td = tr.find_all('span', attrs={'class':'tah p11'})\n",
    "            # print(\"for tr type : %s\" % type(td))\n",
    "            for x in td :\n",
    "                # print(\"for x in td : %s\" % type(x)) # ---> for tr type : <class 'bs4.element.ResultSet'>\n",
    "                # print(\"for x.contents in td : %s, %s\" % (type(x.contents), x.contents)) # ---> for x.contents in td : <class 'list'>\n",
    "                # print(\"for x.contents in td : %s, %s\" % (type(x.contents[0]), x.contents[0])) # ---> for x.contents in td : <class 'list'>\n",
    "                # time.sleep(3)\n",
    "                # ----> 테이블 중간에 전일비 값이 0이면 table이 엉망이 됨\n",
    "                # ----> 전일비가 안들어오다가 들어간o\n",
    "                # print(\"X Contennts : %s, %s\" % (x.contents[0], type(x.contents[0])))\n",
    "                # print(\"X Contennts : %s, %s\" % (x.contents[0], type(str(x.contents[0]))))\n",
    "                if str(x.contents[0]) == \"0\" :\n",
    "                    continue\n",
    "                else :\n",
    "                    testlist.append(x.contents[0])\n",
    "            \n",
    "        # print(\"# TEST LIST\")\n",
    "        # print(testlist)\n",
    "\n",
    "        for x in range(0, len(testlist)) :\n",
    "            # print(x, testlist[x])\n",
    "            if x == 0 :\n",
    "                closing_list.append(testlist[x])\n",
    "            else :\n",
    "                result = x % 5\n",
    "                if result == 0 :\n",
    "                    closing_list.append(testlist[x])\n",
    "\n",
    "    # print(\"############## date_list ##################\")\n",
    "    # print(date_list)\n",
    "    # print(\"############## closing_list ##################\")\n",
    "    # print(closing_list)\n",
    "\n",
    "    return date_list, closing_list\n",
    "\n",
    "############################################################\n",
    "def __Market_Price(company_code, page):\n",
    "    df_list, date_list, closing_list = [], [], []\n",
    "    # print(\"# Market : %s\" % company_code)\n",
    "\n",
    "    print(\"# Company : %s\" % company_code)\n",
    "    page = int(page)\n",
    "    for page_num in range(1, page) :\n",
    "    # for page_num in range(1, 100) :\n",
    "        url_main = \"https://finance.naver.com/sise/sise_index_day.nhn?code=\" + company_code + \"&page=\" + str(page_num)\n",
    "        # print(\"# url : %s\" % url_main)\n",
    "        code_data = pd.read_html(url_main, header=0, skiprows=(6,7,8)) # ---> code data로 출력을 생성하면 NaN이 1개라인이 남음, Type은 <class 'list'>\n",
    "        df_list.append(pd.read_html(url_main)[0]) # ---> List 로 append, 본문[0]과 페이지 출력[1] 부분 중 본문을 출력\n",
    "\n",
    "    df=pd.concat(df_list)\n",
    "    df.dropna(subset=[\"날짜\"], inplace=True) # ---> Naver에서 출력되는 가운데 날짜 컬럼 NaN 라인들 삭제처리\n",
    "    df.rename(columns={'날짜': 'date'}, inplace = True)\n",
    "    df.rename(columns={'체결가': 'closing'}, inplace = True)\n",
    "    df.rename(columns={'전일비': 'diff'}, inplace = True)\n",
    "    df['new_date'] = pd.to_datetime(df['date']) # ---> dateime 형식으로 new_date 추가\n",
    "    date_list=df.date.values.tolist()\n",
    "    closing_list=df.closing.values.tolist()\n",
    "    for x in range(0, len(closing_list)-1):\n",
    "        closing_list[x] = int(closing_list[x]) # ---> float 에서 int로 변경\n",
    "\n",
    "    # date_list.reverse()\n",
    "    # closing_list.reverse()\n",
    "\n",
    "    return date_list, closing_list\n",
    "\n",
    "############################################################\n",
    "def __New_Make_Chart (Dart_Exp_Code, Dart_Comp_Name, Market, Market_Date, Market_List) :\n",
    "\n",
    "    DateTime = datetime.datetime.today().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "    if platform == 'darwin' : # or win32\n",
    "        DateTime = datetime.datetime.today().strftime(\"%Y%m%d_%H%M\")\n",
    "        File_Name = \"/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/\"+Dart_Comp_Name+\".html\"\n",
    "        input_1 = open('/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/New_Echart_Test_1.html', 'r') # Echrt의 머릿글\n",
    "        output = open(File_Name, 'w+t')\n",
    "    else :\n",
    "        DateTime_Win = datetime.datetime.today().strftime(\"%Y%m%d\")\n",
    "        File_Name = Dart_Comp_Name+\".html\"\n",
    "        input_1 = open('New_Echart_Test_1.html', 'r', encoding='utf-8') # Echrt의 머릿글\n",
    "        output = open(File_Name, 'w+t', encoding='utf-8')\n",
    "\n",
    "    # 아래는 Make_Chart를 위한 조건들\n",
    "    Comp_Date_List, KOSPI_DATE_List, KOSDAQ_DATE_List = [], [], []\n",
    "    Comp_Closing_List, KOSPI_List, KOSDAQ_List = [], [], []\n",
    "\n",
    "    Exp_page = __Last_Page_Numb(Dart_Exp_Code, 1)\n",
    "    Comp_Date_List, Comp_Closing_List = __Price_Find(Dart_Exp_Code, Exp_page)\n",
    "    date_list = Comp_Date_List\n",
    "\n",
    "    print(\"Market : %s\" % Market)\n",
    "\n",
    "    # if Market == \"코스피\" :\n",
    "    #     KOSPI_Page = __Last_Page_Numb_Market(\"KOSPI\")\n",
    "    #     KOSPI_Date, KOSPI_List = __Market_Price(\"KOSPI\", KOSPI_Page)\n",
    "    #     closing_list_A = KOSPI_List\n",
    "    #     closing_list_B = Comp_Closing_List\n",
    "    # elif Market == \"코스닥\" :\n",
    "    #     KOSDAQ_Page = __Last_Page_Numb_Market(\"KOSDAQ\")\n",
    "    #     KOSDAQ_Date, KOSDAQ_List = __Market_Price(\"KOSDAQ\", KOSDAQ_Page)\n",
    "    #     closing_list_A = KOSDAQ_List\n",
    "    #     closing_list_B = Comp_Closing_List\n",
    "\n",
    "    closing_list_A = Market_List\n",
    "    closing_list_B = Comp_Closing_List\n",
    "\n",
    "    n = len(closing_list_B)\n",
    "    print(\"date list 0 : %s\" % date_list[0])\n",
    "    print(\"date leng : %s\" % len(date_list))\n",
    "    print(\"closing list A-0 : %s \" % closing_list_A[0])\n",
    "    print(\"closing leng A : %s \" % len(closing_list_A))\n",
    "    print(\"closong list B-0 : %s \" % closing_list_B[0])\n",
    "    print(\"closing leng B : %s \" % len(closing_list_B))\n",
    "    del date_list[n:]\n",
    "    del closing_list_A[n:]\n",
    "    del closing_list_B[n:]\n",
    "    print(\"# After DEL\")\n",
    "    print(\"date list 0 : %s\" % date_list[0])\n",
    "    print(\"closing list A-0 : %s \" % closing_list_A[0])\n",
    "    print(\"closing leng A : %s \" % len(closing_list_A))\n",
    "    print(\"closong list B-0 : %s \" % closing_list_B[0])\n",
    "    print(\"closing leng B : %s \" % len(closing_list_B))\n",
    "\n",
    "    # ls = [type(item) for item in closing_list_A]\n",
    "    # print(ls) # ---> int\n",
    "    # ls = [type(item) for item in closing_list_B]\n",
    "    # print(ls) # ---> <class 'bs4.element.NavigableString'>\n",
    "    # 천 단위 , 자리수가 있으면 string이고 없으면 int 로 list 생성되는듯..\n",
    "\n",
    "    for idx, val in enumerate(closing_list_A) :\n",
    "        if type(closing_list_A[idx]) == int or type(closing_list_A[idx]) == float :\n",
    "            continue\n",
    "        else :\n",
    "            val = val.replace(\",\",\"\")\n",
    "            closing_list_A[idx] = val\n",
    "\n",
    "    for idx, val in enumerate(closing_list_B) :\n",
    "        if type(closing_list_B[idx]) == int or type(closing_list_B[idx]) == float :\n",
    "            continue\n",
    "        else :\n",
    "            val = val.replace(\",\",\"\")\n",
    "            closing_list_B[idx] = val\n",
    "\n",
    "    # print(date_list.reverse()) # ---> None\n",
    "    # print(reversed(date_list)) # ---> <list_reverseiterator object at 0x12235bbb0>\n",
    "    # date_list.reverse() # ---> None\n",
    "    # print(reversed(date_list)) # ---> <list_reverseiterator object at 0x1190a7d00>\n",
    "    # print(date_list[::-1]) # ---> OK\n",
    "\n",
    "    # max_value_A = int(max(closing_list_A)) * 2\n",
    "    # max_value_B = int(max(closing_list_B)) * 2\n",
    "    numrow_A = [float(x) for x in closing_list_A]\n",
    "    max_value_A = int(max(numrow_A)) * 1.5\n",
    "    numrow_B = [float(x) for x in closing_list_B]\n",
    "    max_value_B = int(max(numrow_B)) * 1.5 # ---> ValueError: could not convert string to float: '11,550'\n",
    "\n",
    "    print(\"# MAKE HTML Start\")\n",
    "    for line in input_1.readlines():\n",
    "        output.write(line)\n",
    "    output.write(\"        data: ['%s', '%s']\\n\" % (Market, Dart_Comp_Name))\n",
    "    output.write(\"    },\\n\")\n",
    "    output.write(\"    xAxis: [\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            type: 'category',\\n\")\n",
    "    output.write(\"            axisTick: {\\n\")\n",
    "    output.write(\"                alignWithLabel: true\\n\")\n",
    "    output.write(\"            },\\n\")\n",
    "    output.write(\"            data: [\")\n",
    "    for item in date_list[::-1] :\n",
    "        output.write(\"'%s',\" % item)\n",
    "    output.write(\"        ]\\n\")\n",
    "    output.write(\"        }\\n\")\n",
    "    output.write(\"    ],\\n\")\n",
    "    output.write(\"    yAxis: [\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            type: 'value',\\n\")\n",
    "    output.write(\"            name: '%s',\\n\" % Market)\n",
    "    output.write(\"            min: 0,\\n\")\n",
    "    output.write(\"            max: %s,\\n\" % str(max_value_A))\n",
    "    output.write(\"            position: 'right',\\n\")\n",
    "    output.write(\"            axisLine: {\\n\")\n",
    "    output.write(\"                lineStyle: {\\n\")\n",
    "    output.write(\"                    color: colors[0]\\n\")\n",
    "    output.write(\"                }\\n\")\n",
    "    output.write(\"            },\\n\")\n",
    "    output.write(\"            axisLabel: {\\n\")\n",
    "    output.write(\"                formatter: '{value} 원'\\n\")\n",
    "    output.write(\"            }\\n\")\n",
    "    output.write(\"        },\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            type: 'value',\\n\")\n",
    "    output.write(\"            name: '%s',\\n\" % Dart_Comp_Name)\n",
    "    output.write(\"            min: 0,\\n\")\n",
    "    output.write(\"            max: %s,\\n\" % str(max_value_B))\n",
    "    output.write(\"            position: 'left',\\n\")\n",
    "    output.write(\"            axisLine: {\\n\")\n",
    "    output.write(\"                lineStyle: {\\n\")\n",
    "    output.write(\"                    color: colors[1]\\n\")\n",
    "    output.write(\"                }\\n\")\n",
    "    output.write(\"            },\\n\")\n",
    "    output.write(\"            axisLabel: {\\n\")\n",
    "    output.write(\"                formatter: '{value} 원'\\n\")\n",
    "    output.write(\"            }\\n\")\n",
    "    output.write(\"        }\\n\")\n",
    "    output.write(\"    ],\\n\")\n",
    "    output.write(\"    series: [\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            name: '%s',\\n\" % Market)\n",
    "    output.write(\"            type: 'line',\\n\")\n",
    "    output.write(\"              data: [\\n\")\n",
    "    for x in closing_list_A[::-1] :\n",
    "        output.write(\"'%s',\" % x)\n",
    "    output.write(\"        ]\\n\")\n",
    "    output.write(\"        },\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            name: '%s',\\n\" % Dart_Comp_Name)\n",
    "    output.write(\"            type: 'line',\\n\")\n",
    "    output.write(\"            yAxisIndex: 1,\\n\")\n",
    "    output.write(\"              data: [\\n\")\n",
    "    for x in closing_list_B[::-1]  :\n",
    "        output.write(\"'%s',\" % x)\n",
    "    output.write(\"    ]\\n\")\n",
    "    output.write(\"        }\\n\")\n",
    "    output.write(\"    ]\\n\")\n",
    "    output.write(\"};\\n\")\n",
    "    output.write(\"        // use configuration item and data specified to show chart\\n\")\n",
    "    output.write(\"        myChart.setOption(option);\\n\")\n",
    "    output.write(\"    </script>\\n\")\n",
    "    output.write(\"</body>\\n\")\n",
    "\n",
    "    # for line in input_2.readlines():\n",
    "        # output.write(line)\n",
    "\n",
    "    print(\"# MAKE HTML Done\")\n",
    "\n",
    "    output.close()\n",
    "\n",
    "    #read input file\n",
    "    if platform != 'darwin' :\n",
    "        with codecs.open(File_Name, 'r', encoding = 'utf8') as file:\n",
    "            lines = file.read()\n",
    "        #write output file\n",
    "        with codecs.open(File_Name, 'w', encoding = 'utf8') as file:\n",
    "            file.write(lines)\n",
    "\n",
    "############################################################\n",
    "if(__name__ == '__main__') :\n",
    "\n",
    "    Stock_Dictionary = {\n",
    "        '코드' : ['160580', '138910', '225130', '225130'],\n",
    "        '종목명' : ['Tiger구리선물', 'KODEX구리선물', 'KINDEX골드선물레버', 'KODEX WTI원유선물'],\n",
    "        'File_Name' : ['TigerCooper', 'KodexCooper', 'KindexGold', 'KodexWTI'],\n",
    "    }\n",
    "\n",
    "    Dart_Market_Name = '코스피'\n",
    "    # Dart_Market_Name = '코스닥'\n",
    "\n",
    "    KOSPI_Page = __Last_Page_Numb_Market(\"KOSPI\")\n",
    "    print(\"# KOSPI Page : %s\" % KOSPI_Page)\n",
    "    KOSPI_Date, KOSPI_List = __Market_Price(\"KOSPI\", KOSPI_Page)\n",
    "\n",
    "    # print(\"# KOSPI DATE\")\n",
    "    # print(len(KOSPI_Date))\n",
    "    # print(KOSPI_Date)\n",
    "    # print(\"# KOSPI List\")\n",
    "    # print(len(KOSPI_List))\n",
    "    # print(KOSPI_List)\n",
    "\n",
    "    # KOSDAQ_Page = __Last_Page_Numb_Market(\"KOSDAQ\")\n",
    "    print(\"# KOSDAQ Page : %s\" % KOSPI_Page)\n",
    "    # KOSDAQ_Date, KOSDAQ_List = __Market_Price(\"KOSDAQ\", KOSDAQ_Page)\n",
    "\n",
    "    Stock_Dic = pd.DataFrame(Stock_Dictionary)\n",
    "    print(Stock_Dic)\n",
    "\n",
    "    for index, row in Stock_Dic.iterrows():\n",
    "        print(\"%s차 FOR문 시작\" % index)\n",
    "        Exp_page = __Last_Page_Numb(row['코드'], 1)\n",
    "        Dart_Exp_Code = row['코드']\n",
    "        Comp_Date_List, Comp_Closing_List = __Price_Find(Dart_Exp_Code, Exp_page)\n",
    "\n",
    "        print(\"# Comp Date List\" )\n",
    "        print(len(Comp_Date_List))\n",
    "        print(Comp_Date_List)\n",
    "        print(\"# Comp Closing List\")\n",
    "        print(len(Comp_Closing_List))\n",
    "        print(Comp_Closing_List)\n",
    "\n",
    "        __New_Make_Chart(Dart_Exp_Code, row['종목명'], Dart_Market_Name, KOSPI_Date, KOSPI_List)\n",
    "\n",
    "        print(\"%s차 FOR문 끝\" % index)\n",
    "\n",
    "    print(\"# Program End\")\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.error import HTTPError\n",
    "from urllib.parse import quote\n",
    "from matplotlib import pyplot as plt\n",
    "from sys import platform\n",
    "import bs4, ssl\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime, time # for sleep\n",
    "import requests\n",
    "import numpy as np\n",
    "import io\n",
    "import codecs\n",
    "\n",
    "import xml.etree.ElementTree as et \n",
    "\n",
    "import json\n",
    "import urllib\n",
    "import urllib.request\n",
    "import sys\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                            'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                            'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "            'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "            'Accept-Encoding': 'none', \\\n",
    "            'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "            'Connection': 'keep-alive'}\n",
    "\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "############################################################\n",
    "def __Last_Page_Find(i, Market) :\n",
    "    # print(\"# Last_Page_Find Start\")\n",
    "    if Market == 1 :\n",
    "        url = \"https://finance.naver.com/sise/sise_market_sum.nhn?&page=\" + str(i)\n",
    "    else :\n",
    "        url = \"https://finance.naver.com/sise/sise_market_sum.nhn?sosok=1&page=\" + str(i)\n",
    "    # print(\"# print URL\")\n",
    "    # print(url) # ---> 당시의 위치정보를 기반으로 15페이지 가져오는 듯, 어찌 가져오는지는 모르겠음...(2020.05.21)\n",
    "    # ---> HTTP Error 403: Forbidden\n",
    "    # headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\n",
    "    # req = Request(url=url, headers={'User-Agent': 'Mozilla/5.0', 'referer': 'http://m.naver.com'})\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "                             'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "                             'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "               'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "               'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "               'Accept-Encoding': 'none', \\\n",
    "               'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "               'Connection': 'keep-alive'}\n",
    "    req = Request(url=url, headers=headers)\n",
    "\n",
    "    try :\n",
    "        html = urlopen(req).read()\n",
    "        # html = urlopen(url, context=context)\n",
    "    except HTTPError as err:\n",
    "        if err.code == 404 :\n",
    "            print(\"# Error HTTP : 404\")\n",
    "            return\n",
    "        elif err.code == 403 :\n",
    "            print(\"# Error HTTP : 403\")\n",
    "            return\n",
    "        elif err.code == 500 :\n",
    "            print(\"# Error HTTP : 500\")\n",
    "            return\n",
    "        elif err.code == 505:\n",
    "            print(\"# Error HTTP : 505\")\n",
    "            return\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    # test = bs_object.find('table' ,attrs={'class':'type_2'})\n",
    "    # numbersss = test.findAll(\"td\", {\"class\": \"number\"})\n",
    "    # print(numbersss)\n",
    "\n",
    "    data = []\n",
    "    table = bs_object.find('table', attrs={'class':'type_2'})\n",
    "    table_body = table.find('tbody')\n",
    "    rows = table_body.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
    "    # print(\"##################\")\n",
    "    # for x in data :\n",
    "        # print(x)\n",
    "\n",
    "    # print(\"##########################################\")\n",
    "    # print(type(data))\n",
    "    Data_DF = pd.DataFrame(data, columns=['No','회사명','현재가','전일비','등락률','액면가','시가총액','상장주식수','외국인비율','거래량','PER','ROE'])\n",
    "    # print(type(data_df))\n",
    "    # print(data_df)\n",
    "    # print(\"# Drop NA\")\n",
    "    Data_DF = Data_DF.dropna()\n",
    "    Data_DF = Data_DF[['No','회사명','ROE','PER','외국인비율','현재가']]\n",
    "    if Market == 1 :\n",
    "        Data_DF['Market'] = \"코스피\"\n",
    "    else :\n",
    "        Data_DF['Market'] = \"코스닥\"\n",
    "\n",
    "    return Data_DF\n",
    "\n",
    "############################################################\n",
    "def __Last_Page_Numb(company_code, dist) :\n",
    "\n",
    "    if dist == 1 :\n",
    "        url = \"https://finance.naver.com/item/sise_day.nhn?code=\" + company_code\n",
    "    else :\n",
    "        url = \"https://finance.naver.com/research/company_list.nhn?searchType=itemCode&itemCode=\" + company_code\n",
    "    \n",
    "    print(url)\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) ' \\\n",
    "        'AppleWebKit/537.11 (KHTML, like Gecko) ' \\\n",
    "        'Chrome/23.0.1271.64 Safari/537.11', \\\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', \\\n",
    "        'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', \\\n",
    "        'Accept-Encoding': 'none', \\\n",
    "        'Accept-Language': 'en-US,en;q=0.8', \\\n",
    "        'Connection': 'keep-alive'}\n",
    "\n",
    "    req = Request(url=url, headers=headers)\n",
    "    html = urlopen(req).read()\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    table = bs_object.find('td', attrs={'class':'pgRR'})\n",
    "    if table is None :\n",
    "        print(\"# Naver Report 없음\")\n",
    "        return 10000\n",
    "\n",
    "    print(table)\n",
    "\n",
    "    for x in table.find_all('a') :\n",
    "        test = x['href']\n",
    "        active = test.split(\"=\")\n",
    "        if dist == 1 :\n",
    "            page_num = active[2]\n",
    "        else :\n",
    "            page_num = active[3]\n",
    "\n",
    "    if dist == 1 :\n",
    "        print(\"# Company Page_Number : \", page_num)\n",
    "    else :\n",
    "        print(\"# Report Page_Number : \", page_num)\n",
    "\n",
    "    return page_num\n",
    "############################################################\n",
    "def __Last_Page_Numb_Market(Market) :\n",
    "    if Market == \"KOSPI\" :\n",
    "        url = \"https://finance.naver.com/sise/sise_index_day.nhn?code=KOSPI&page=1\"\n",
    "        # print(url)\n",
    "    elif Market == \"KOSDAQ\" :\n",
    "        url = \"https://finance.naver.com/sise/sise_index_day.nhn?code=KOSDAQ&page=1\"\n",
    "        # print(url)\n",
    "    print(\"Market : %s\" % url)\n",
    "\n",
    "    html = urlopen(url, context=context)\n",
    "    bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    main1_pages = bs_object.find_all(\"a\")\n",
    "    for a_list in main1_pages:\n",
    "        if a_list is main1_pages[-1] :\n",
    "            last_page=a_list.attrs['href']\n",
    "        else :\n",
    "            continue\n",
    "        page_num: object=last_page.split('=')\n",
    "        print(\"# Market Page_Number : \", page_num[2])\n",
    "        return page_num[2]\n",
    "\n",
    "############################################################\n",
    "def __Price_Find(company_code, page):\n",
    "    page = int(page)\n",
    "    df_list, date_list, closing_list, gap_list, gap_perf  = [], [], [], [], []\n",
    "\n",
    "    date_list, closing_list = [], []\n",
    "    for page_num in range(1, page) :\n",
    "    # for page_num in range(1, 125) : # ---> 1페이지 당 10일, 250일이 년중 평일이라 하면 25페이지가 1년, 125페이지가 5년.\n",
    "        url= \"https://finance.naver.com/item/sise_day.nhn?code=\" + company_code + \"&page=\" + str(page_num)\n",
    "        print(url)\n",
    "\n",
    "        req = Request(url=url, headers=headers)\n",
    "\n",
    "        try :\n",
    "            html = urlopen(req).read()\n",
    "            # html = urlopen(url, context=context)\n",
    "        except HTTPError as err:\n",
    "            if err.code == 404 :\n",
    "                print(\"# Error HTTP : 404\")\n",
    "                return\n",
    "            elif err.code == 403 :\n",
    "                print(\"# Error HTTP : 403\")\n",
    "                return\n",
    "            elif err.code == 500 :\n",
    "                print(\"# Error HTTP : 500\")\n",
    "                return\n",
    "            elif err.code == 505:\n",
    "                print(\"# Error HTTP : 505\")\n",
    "                return\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        bs_object = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "        table = bs_object.find('table', attrs={'class':'type2'})\n",
    "        table_body = table.find_all('td', attrs={'class':'num'})\n",
    "        date_body = table.find_all('span', attrs={'class':'tah p10 gray03'})\n",
    "\n",
    "        for x in date_body :\n",
    "            # print(\"x.contents type : %s\" % type(x.contents)) # ---> x.contents type : <class 'list'>\n",
    "            date_list.append(x.contents[0])\n",
    "\n",
    "        testlist = []\n",
    "        for tr in table_body :\n",
    "            td = tr.find_all('span', attrs={'class':'tah p11'})\n",
    "            # print(\"for tr type : %s\" % type(td))\n",
    "            for x in td :\n",
    "                # print(\"for x in td : %s\" % type(x)) # ---> for tr type : <class 'bs4.element.ResultSet'>\n",
    "                # print(\"for x.contents in td : %s, %s\" % (type(x.contents), x.contents)) # ---> for x.contents in td : <class 'list'>\n",
    "                # print(\"for x.contents in td : %s, %s\" % (type(x.contents[0]), x.contents[0])) # ---> for x.contents in td : <class 'list'>\n",
    "                # time.sleep(3)\n",
    "                # ----> 테이블 중간에 전일비 값이 0이면 table이 엉망이 됨\n",
    "                # ----> 전일비가 안들어오다가 들어간o\n",
    "                # print(\"X Contennts : %s, %s\" % (x.contents[0], type(x.contents[0])))\n",
    "                # print(\"X Contennts : %s, %s\" % (x.contents[0], type(str(x.contents[0]))))\n",
    "                if str(x.contents[0]) == \"0\" :\n",
    "                    continue\n",
    "                else :\n",
    "                    testlist.append(x.contents[0])\n",
    "            \n",
    "        # print(\"# TEST LIST\")\n",
    "        # print(testlist)\n",
    "\n",
    "        for x in range(0, len(testlist)) :\n",
    "            # print(x, testlist[x])\n",
    "            if x == 0 :\n",
    "                closing_list.append(testlist[x])\n",
    "            else :\n",
    "                result = x % 5\n",
    "                if result == 0 :\n",
    "                    closing_list.append(testlist[x])\n",
    "\n",
    "    # print(\"############## date_list ##################\")\n",
    "    # print(date_list)\n",
    "    # print(\"############## closing_list ##################\")\n",
    "    # print(closing_list)\n",
    "\n",
    "    return date_list, closing_list\n",
    "\n",
    "############################################################\n",
    "def __Market_Price(company_code, page):\n",
    "    df_list, date_list, closing_list = [], [], []\n",
    "    # print(\"# Market : %s\" % company_code)\n",
    "\n",
    "    print(\"# Company : %s\" % company_code)\n",
    "    page = int(page)\n",
    "    for page_num in range(1, page) :\n",
    "    # for page_num in range(1, 100) :\n",
    "        url_main = \"https://finance.naver.com/sise/sise_index_day.nhn?code=\" + company_code + \"&page=\" + str(page_num)\n",
    "        # print(\"# url : %s\" % url_main)\n",
    "        code_data = pd.read_html(url_main, header=0, skiprows=(6,7,8)) # ---> code data로 출력을 생성하면 NaN이 1개라인이 남음, Type은 <class 'list'>\n",
    "        df_list.append(pd.read_html(url_main)[0]) # ---> List 로 append, 본문[0]과 페이지 출력[1] 부분 중 본문을 출력\n",
    "\n",
    "    df=pd.concat(df_list)\n",
    "    df.dropna(subset=[\"날짜\"], inplace=True) # ---> Naver에서 출력되는 가운데 날짜 컬럼 NaN 라인들 삭제처리\n",
    "    df.rename(columns={'날짜': 'date'}, inplace = True)\n",
    "    df.rename(columns={'체결가': 'closing'}, inplace = True)\n",
    "    df.rename(columns={'전일비': 'diff'}, inplace = True)\n",
    "    df['new_date'] = pd.to_datetime(df['date']) # ---> dateime 형식으로 new_date 추가\n",
    "    date_list=df.date.values.tolist()\n",
    "    closing_list=df.closing.values.tolist()\n",
    "    for x in range(0, len(closing_list)-1):\n",
    "        closing_list[x] = int(closing_list[x]) # ---> float 에서 int로 변경\n",
    "\n",
    "    # date_list.reverse()\n",
    "    # closing_list.reverse()\n",
    "\n",
    "    return date_list, closing_list\n",
    "\n",
    "############################################################\n",
    "def __New_Make_Chart (Dart_Exp_Code, Dart_Comp_Name, Market, Market_Date, Market_List) :\n",
    "\n",
    "    DateTime = datetime.datetime.today().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "    if platform == 'darwin' : # or win32\n",
    "        DateTime = datetime.datetime.today().strftime(\"%Y%m%d_%H%M\")\n",
    "        File_Name = \"/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/\"+Dart_Comp_Name+\".html\"\n",
    "        input_1 = open('/Users/choiyoungmin/PycharmProjects/2020Y/Anal_Comp/New_Echart_Test_1.html', 'r') # Echrt의 머릿글\n",
    "    else :\n",
    "        DateTime_Win = datetime.datetime.today().strftime(\"%Y%m%d\")\n",
    "        File_Name = Dart_Comp_Name+\".html\"\n",
    "        input_1 = open('New_Echart_Test_1.html', 'r') # Echrt의 머릿글\n",
    "\n",
    "    # 아래는 Make_Chart를 위한 조건들\n",
    "    Comp_Date_List, KOSPI_DATE_List, KOSDAQ_DATE_List = [], [], []\n",
    "    Comp_Closing_List, KOSPI_List, KOSDAQ_List = [], [], []\n",
    "\n",
    "    Exp_page = __Last_Page_Numb(Dart_Exp_Code, 1)\n",
    "    Comp_Date_List, Comp_Closing_List = __Price_Find(Dart_Exp_Code, Exp_page)\n",
    "    date_list = Comp_Date_List\n",
    "\n",
    "    print(\"Market : %s\" % Market)\n",
    "\n",
    "    # if Market == \"코스피\" :\n",
    "    #     KOSPI_Page = __Last_Page_Numb_Market(\"KOSPI\")\n",
    "    #     KOSPI_Date, KOSPI_List = __Market_Price(\"KOSPI\", KOSPI_Page)\n",
    "    #     closing_list_A = KOSPI_List\n",
    "    #     closing_list_B = Comp_Closing_List\n",
    "    # elif Market == \"코스닥\" :\n",
    "    #     KOSDAQ_Page = __Last_Page_Numb_Market(\"KOSDAQ\")\n",
    "    #     KOSDAQ_Date, KOSDAQ_List = __Market_Price(\"KOSDAQ\", KOSDAQ_Page)\n",
    "    #     closing_list_A = KOSDAQ_List\n",
    "    #     closing_list_B = Comp_Closing_List\n",
    "\n",
    "    closing_list_A = Market_List\n",
    "    closing_list_B = Comp_Closing_List\n",
    "\n",
    "    n = len(closing_list_B)\n",
    "    print(\"date list 0 : %s\" % date_list[0])\n",
    "    print(\"date leng : %s\" % len(date_list))\n",
    "    print(\"closing list A-0 : %s \" % closing_list_A[0])\n",
    "    print(\"closing leng A : %s \" % len(closing_list_A))\n",
    "    print(\"closong list B-0 : %s \" % closing_list_B[0])\n",
    "    print(\"closing leng B : %s \" % len(closing_list_B))\n",
    "    del date_list[n:]\n",
    "    del closing_list_A[n:]\n",
    "    del closing_list_B[n:]\n",
    "    print(\"# After DEL\")\n",
    "    print(\"date list 0 : %s\" % date_list[0])\n",
    "    print(\"closing list A-0 : %s \" % closing_list_A[0])\n",
    "    print(\"closing leng A : %s \" % len(closing_list_A))\n",
    "    print(\"closong list B-0 : %s \" % closing_list_B[0])\n",
    "    print(\"closing leng B : %s \" % len(closing_list_B))\n",
    "\n",
    "    output = open(File_Name, 'w+t', encoding='utf-8')\n",
    "\n",
    "    # ls = [type(item) for item in closing_list_A]\n",
    "    # print(ls) # ---> int\n",
    "    # ls = [type(item) for item in closing_list_B]\n",
    "    # print(ls) # ---> <class 'bs4.element.NavigableString'>\n",
    "    # 천 단위 , 자리수가 있으면 string이고 없으면 int 로 list 생성되는듯..\n",
    "\n",
    "    for idx, val in enumerate(closing_list_A) :\n",
    "        if type(closing_list_A[idx]) == int or type(closing_list_A[idx]) == float :\n",
    "            continue\n",
    "        else :\n",
    "            val = val.replace(\",\",\"\")\n",
    "            closing_list_A[idx] = val\n",
    "\n",
    "    for idx, val in enumerate(closing_list_B) :\n",
    "        if type(closing_list_B[idx]) == int or type(closing_list_B[idx]) == float :\n",
    "            continue\n",
    "        else :\n",
    "            val = val.replace(\",\",\"\")\n",
    "            closing_list_B[idx] = val\n",
    "\n",
    "    # print(date_list.reverse()) # ---> None\n",
    "    # print(reversed(date_list)) # ---> <list_reverseiterator object at 0x12235bbb0>\n",
    "    # date_list.reverse() # ---> None\n",
    "    # print(reversed(date_list)) # ---> <list_reverseiterator object at 0x1190a7d00>\n",
    "    # print(date_list[::-1]) # ---> OK\n",
    "\n",
    "    # max_value_A = int(max(closing_list_A)) * 2\n",
    "    # max_value_B = int(max(closing_list_B)) * 2\n",
    "    numrow_A = [float(x) for x in closing_list_A]\n",
    "    max_value_A = int(max(numrow_A)) * 1.5\n",
    "    numrow_B = [float(x) for x in closing_list_B]\n",
    "    max_value_B = int(max(numrow_B)) * 1.5 # ---> ValueError: could not convert string to float: '11,550'\n",
    "\n",
    "    print(\"# MAKE HTML Start\")\n",
    "    for line in input_1.readlines():\n",
    "        output.write(line)\n",
    "    output.write(\"        data: ['%s', '%s']\\n\" % (Market, Dart_Comp_Name))\n",
    "    output.write(\"    },\\n\")\n",
    "    output.write(\"    xAxis: [\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            type: 'category',\\n\")\n",
    "    output.write(\"            axisTick: {\\n\")\n",
    "    output.write(\"                alignWithLabel: true\\n\")\n",
    "    output.write(\"            },\\n\")\n",
    "    output.write(\"            data: [\")\n",
    "    for item in date_list[::-1] :\n",
    "        output.write(\"'%s',\" % item)\n",
    "    output.write(\"        ]\\n\")\n",
    "    output.write(\"        }\\n\")\n",
    "    output.write(\"    ],\\n\")\n",
    "    output.write(\"    yAxis: [\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            type: 'value',\\n\")\n",
    "    output.write(\"            name: '%s',\\n\" % Market)\n",
    "    output.write(\"            min: 0,\\n\")\n",
    "    output.write(\"            max: %s,\\n\" % str(max_value_A))\n",
    "    output.write(\"            position: 'right',\\n\")\n",
    "    output.write(\"            axisLine: {\\n\")\n",
    "    output.write(\"                lineStyle: {\\n\")\n",
    "    output.write(\"                    color: colors[0]\\n\")\n",
    "    output.write(\"                }\\n\")\n",
    "    output.write(\"            },\\n\")\n",
    "    output.write(\"            axisLabel: {\\n\")\n",
    "    output.write(\"                formatter: '{value} 원'\\n\")\n",
    "    output.write(\"            }\\n\")\n",
    "    output.write(\"        },\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            type: 'value',\\n\")\n",
    "    output.write(\"            name: '%s',\\n\" % Dart_Comp_Name)\n",
    "    output.write(\"            min: 0,\\n\")\n",
    "    output.write(\"            max: %s,\\n\" % str(max_value_B))\n",
    "    output.write(\"            position: 'left',\\n\")\n",
    "    output.write(\"            axisLine: {\\n\")\n",
    "    output.write(\"                lineStyle: {\\n\")\n",
    "    output.write(\"                    color: colors[1]\\n\")\n",
    "    output.write(\"                }\\n\")\n",
    "    output.write(\"            },\\n\")\n",
    "    output.write(\"            axisLabel: {\\n\")\n",
    "    output.write(\"                formatter: '{value} 원'\\n\")\n",
    "    output.write(\"            }\\n\")\n",
    "    output.write(\"        }\\n\")\n",
    "    output.write(\"    ],\\n\")\n",
    "    output.write(\"    series: [\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            name: '%s',\\n\" % Market)\n",
    "    output.write(\"            type: 'line',\\n\")\n",
    "    output.write(\"              data: [\\n\")\n",
    "    for x in closing_list_A[::-1] :\n",
    "        output.write(\"'%s',\" % x)\n",
    "    output.write(\"        ]\\n\")\n",
    "    output.write(\"        },\\n\")\n",
    "    output.write(\"        {\\n\")\n",
    "    output.write(\"            name: '%s',\\n\" % Dart_Comp_Name)\n",
    "    output.write(\"            type: 'line',\\n\")\n",
    "    output.write(\"            yAxisIndex: 1,\\n\")\n",
    "    output.write(\"              data: [\\n\")\n",
    "    for x in closing_list_B[::-1]  :\n",
    "        output.write(\"'%s',\" % x)\n",
    "    output.write(\"    ]\\n\")\n",
    "    output.write(\"        }\\n\")\n",
    "    output.write(\"    ]\\n\")\n",
    "    output.write(\"};\\n\")\n",
    "    output.write(\"        // use configuration item and data specified to show chart\\n\")\n",
    "    output.write(\"        myChart.setOption(option);\\n\")\n",
    "    output.write(\"    </script>\\n\")\n",
    "    output.write(\"</body>\\n\")\n",
    "\n",
    "    # for line in input_2.readlines():\n",
    "        # output.write(line)\n",
    "\n",
    "    print(\"# MAKE HTML Done\")\n",
    "\n",
    "    output.close()\n",
    "\n",
    "    #read input file\n",
    "    if platform != 'darwin' :\n",
    "        with codecs.open(File_Name, 'r', encoding = 'utf8') as file:\n",
    "            lines = file.read()\n",
    "        #write output file\n",
    "        with codecs.open(File_Name, 'w', encoding = 'utf8') as file:\n",
    "            file.write(lines)\n",
    "\n",
    "############################################################\n",
    "if(__name__ == '__main__') :\n",
    "\n",
    "    print(\"##############################\")\n",
    "    start = time.time()\n",
    "    print(start)\n",
    "    \n",
    "    Stock_Dictionary = {\n",
    "        '코드' : ['160580', '138910', '225130', '225130'],\n",
    "        '종목명' : ['Tiger구리선물', 'KODEX구리선물', 'KINDEX골드선물레버', 'KODEX-WTI원유선물'],\n",
    "        'File_Name' : ['TigerCooper', 'KodexCooper', 'KindexGold', 'KodexWTI'],\n",
    "    }\n",
    "\n",
    "    Dart_Market_Name = '코스피'\n",
    "    # Dart_Market_Name = '코스닥'\n",
    "\n",
    "    print(\"##############################\")\n",
    "    print(Dart_Market_Name)\n",
    "    print(\"##############################\")\n",
    "    KOSPI_Page = __Last_Page_Numb_Market(\"KOSPI\")\n",
    "    print(\"# KOSPI Page : %s\" % KOSPI_Page)\n",
    "    KOSPI_Date, KOSPI_List = __Market_Price(\"KOSPI\", KOSPI_Page)\n",
    "\n",
    "    # print(\"# KOSPI DATE\")\n",
    "    # print(len(KOSPI_Date))\n",
    "    # print(KOSPI_Date)\n",
    "    # print(\"# KOSPI List\")\n",
    "    # print(len(KOSPI_List))\n",
    "    # print(KOSPI_List)\n",
    "\n",
    "    # KOSDAQ_Page = __Last_Page_Numb_Market(\"KOSDAQ\")\n",
    "    print(\"# KOSDAQ Page : %s\" % KOSPI_Page)\n",
    "    # KOSDAQ_Date, KOSDAQ_List = __Market_Price(\"KOSDAQ\", KOSDAQ_Page)\n",
    "\n",
    "    Stock_Dic = pd.DataFrame(Stock_Dictionary)\n",
    "    print(Stock_Dic)\n",
    "\n",
    "    for index, row in Stock_Dic.iterrows():\n",
    "        print(\"%s차 FOR문 시작\" % index)\n",
    "        Exp_page = __Last_Page_Numb(row['코드'], 1)\n",
    "        Dart_Exp_Code = row['코드']\n",
    "        Comp_Date_List, Comp_Closing_List = __Price_Find(Dart_Exp_Code, Exp_page)\n",
    "\n",
    "        print(\"# Comp Date List\" )\n",
    "        print(len(Comp_Date_List))\n",
    "        print(Comp_Date_List)\n",
    "        print(\"# Comp Closing List\")\n",
    "        print(len(Comp_Closing_List))\n",
    "        print(Comp_Closing_List)\n",
    "\n",
    "        __New_Make_Chart(Dart_Exp_Code, row['종목명'], Dart_Market_Name, KOSPI_Date, KOSPI_List)\n",
    "\n",
    "        print(\"%s차 FOR문 끝\" % index)\n",
    "\n",
    "    print(\"# Program End\")\n",
    "    print(\"it took : %s sec\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
